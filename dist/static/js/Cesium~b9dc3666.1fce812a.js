(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["Cesium~b9dc3666"],{"001c":function(e,n,t){"use strict";n["a"]="#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n\n#ifdef TEXTURE_COORDINATES\n#ifdef SPHERICAL\nvarying vec4 v_sphericalExtents;\n#else // SPHERICAL\nvarying vec2 v_inversePlaneExtents;\nvarying vec4 v_westPlane;\nvarying vec4 v_southPlane;\n#endif // SPHERICAL\nvarying vec3 v_uvMinAndSphericalLongitudeRotation;\nvarying vec3 v_uMaxAndInverseDistance;\nvarying vec3 v_vMaxAndInverseDistance;\n#endif // TEXTURE_COORDINATES\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif\n\n#ifdef NORMAL_EC\nvec3 getEyeCoordinate3FromWindowCoordinate(vec2 fragCoord, float logDepthOrDepth) {\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(fragCoord, logDepthOrDepth);\n    return eyeCoordinate.xyz / eyeCoordinate.w;\n}\n\nvec3 vectorFromOffset(vec4 eyeCoordinate, vec2 positiveOffset) {\n    vec2 glFragCoordXY = gl_FragCoord.xy;\n    // Sample depths at both offset and negative offset\n    float upOrRightLogDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, (glFragCoordXY + positiveOffset) / czm_viewport.zw));\n    float downOrLeftLogDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, (glFragCoordXY - positiveOffset) / czm_viewport.zw));\n    // Explicitly evaluate both paths\n    // Necessary for multifrustum and for edges of the screen\n    bvec2 upOrRightInBounds = lessThan(glFragCoordXY + positiveOffset, czm_viewport.zw);\n    float useUpOrRight = float(upOrRightLogDepth > 0.0 && upOrRightInBounds.x && upOrRightInBounds.y);\n    float useDownOrLeft = float(useUpOrRight == 0.0);\n    vec3 upOrRightEC = getEyeCoordinate3FromWindowCoordinate(glFragCoordXY + positiveOffset, upOrRightLogDepth);\n    vec3 downOrLeftEC = getEyeCoordinate3FromWindowCoordinate(glFragCoordXY - positiveOffset, downOrLeftLogDepth);\n    return (upOrRightEC - (eyeCoordinate.xyz / eyeCoordinate.w)) * useUpOrRight + ((eyeCoordinate.xyz / eyeCoordinate.w) - downOrLeftEC) * useDownOrLeft;\n}\n#endif // NORMAL_EC\n\nvoid main(void)\n{\n#ifdef REQUIRES_EC\n    float logDepthOrDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, gl_FragCoord.xy / czm_viewport.zw));\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, logDepthOrDepth);\n#endif\n\n#ifdef REQUIRES_WC\n    vec4 worldCoordinate4 = czm_inverseView * eyeCoordinate;\n    vec3 worldCoordinate = worldCoordinate4.xyz / worldCoordinate4.w;\n#endif\n\n#ifdef TEXTURE_COORDINATES\n    vec2 uv;\n#ifdef SPHERICAL\n    // Treat world coords as a sphere normal for spherical coordinates\n    vec2 sphericalLatLong = czm_approximateSphericalCoordinates(worldCoordinate);\n    sphericalLatLong.y += v_uvMinAndSphericalLongitudeRotation.z;\n    sphericalLatLong.y = czm_branchFreeTernary(sphericalLatLong.y < czm_pi, sphericalLatLong.y, sphericalLatLong.y - czm_twoPi);\n    uv.x = (sphericalLatLong.y - v_sphericalExtents.y) * v_sphericalExtents.w;\n    uv.y = (sphericalLatLong.x - v_sphericalExtents.x) * v_sphericalExtents.z;\n#else // SPHERICAL\n    // Unpack planes and transform to eye space\n    uv.x = czm_planeDistance(v_westPlane, eyeCoordinate.xyz / eyeCoordinate.w) * v_inversePlaneExtents.x;\n    uv.y = czm_planeDistance(v_southPlane, eyeCoordinate.xyz / eyeCoordinate.w) * v_inversePlaneExtents.y;\n#endif // SPHERICAL\n#endif // TEXTURE_COORDINATES\n\n#ifdef PICK\n#ifdef CULL_FRAGMENTS\n    // When classifying translucent geometry, logDepthOrDepth == 0.0\n    // indicates a region that should not be classified, possibly due to there\n    // being opaque pixels there in another buffer.\n    // Check for logDepthOrDepth != 0.0 to make sure this should be classified.\n    if (0.0 <= uv.x && uv.x <= 1.0 && 0.0 <= uv.y && uv.y <= 1.0 || logDepthOrDepth != 0.0) {\n        gl_FragColor.a = 1.0; // 0.0 alpha leads to discard from ShaderSource.createPickFragmentShaderSource\n        czm_writeDepthClamp();\n    }\n#else // CULL_FRAGMENTS\n        gl_FragColor.a = 1.0;\n#endif // CULL_FRAGMENTS\n#else // PICK\n\n#ifdef CULL_FRAGMENTS\n    // When classifying translucent geometry, logDepthOrDepth == 0.0\n    // indicates a region that should not be classified, possibly due to there\n    // being opaque pixels there in another buffer.\n    if (uv.x <= 0.0 || 1.0 <= uv.x || uv.y <= 0.0 || 1.0 <= uv.y || logDepthOrDepth == 0.0) {\n        discard;\n    }\n#endif\n\n#ifdef NORMAL_EC\n    // Compute normal by sampling adjacent pixels in 2x2 block in screen space\n    vec3 downUp = vectorFromOffset(eyeCoordinate, vec2(0.0, 1.0));\n    vec3 leftRight = vectorFromOffset(eyeCoordinate, vec2(1.0, 0.0));\n    vec3 normalEC = normalize(cross(leftRight, downUp));\n#endif\n\n\n#ifdef PER_INSTANCE_COLOR\n\n    vec4 color = czm_gammaCorrect(v_color);\n#ifdef FLAT\n    gl_FragColor = color;\n#else // FLAT\n    czm_materialInput materialInput;\n    materialInput.normalEC = normalEC;\n    materialInput.positionToEyeEC = -eyeCoordinate.xyz;\n    czm_material material = czm_getDefaultMaterial(materialInput);\n    material.diffuse = color.rgb;\n    material.alpha = color.a;\n\n    gl_FragColor = czm_phong(normalize(-eyeCoordinate.xyz), material, czm_lightDirectionEC);\n#endif // FLAT\n\n    // Premultiply alpha. Required for classification primitives on translucent globe.\n    gl_FragColor.rgb *= gl_FragColor.a;\n\n#else // PER_INSTANCE_COLOR\n\n    // Material support.\n    // USES_ is distinct from REQUIRES_, because some things are dependencies of each other or\n    // dependencies for culling but might not actually be used by the material.\n\n    czm_materialInput materialInput;\n\n#ifdef USES_NORMAL_EC\n    materialInput.normalEC = normalEC;\n#endif\n\n#ifdef USES_POSITION_TO_EYE_EC\n    materialInput.positionToEyeEC = -eyeCoordinate.xyz;\n#endif\n\n#ifdef USES_TANGENT_TO_EYE\n    materialInput.tangentToEyeMatrix = czm_eastNorthUpToEyeCoordinates(worldCoordinate, normalEC);\n#endif\n\n#ifdef USES_ST\n    // Remap texture coordinates from computed (approximately aligned with cartographic space) to the desired\n    // texture coordinate system, which typically forms a tight oriented bounding box around the geometry.\n    // Shader is provided a set of reference points for remapping.\n    materialInput.st.x = czm_lineDistance(v_uvMinAndSphericalLongitudeRotation.xy, v_uMaxAndInverseDistance.xy, uv) * v_uMaxAndInverseDistance.z;\n    materialInput.st.y = czm_lineDistance(v_uvMinAndSphericalLongitudeRotation.xy, v_vMaxAndInverseDistance.xy, uv) * v_vMaxAndInverseDistance.z;\n#endif\n\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef FLAT\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#else // FLAT\n    gl_FragColor = czm_phong(normalize(-eyeCoordinate.xyz), material, czm_lightDirectionEC);\n#endif // FLAT\n\n    // Premultiply alpha. Required for classification primitives on translucent globe.\n    gl_FragColor.rgb *= gl_FragColor.a;\n\n#endif // PER_INSTANCE_COLOR\n    czm_writeDepthClamp();\n#endif // PICK\n}\n"},1627:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform sampler2D colorTexture2;\n\nuniform vec2 center;\nuniform float radius;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    vec4 color0 = texture2D(colorTexture, v_textureCoordinates);\n    vec4 color1 = texture2D(colorTexture2, v_textureCoordinates);\n\n    float x = length(gl_FragCoord.xy - center) / radius;\n    float t = smoothstep(0.5, 0.8, x);\n    gl_FragColor = mix(color0 + color1, color1, t);\n}\n"},"1c39":function(e,n,t){"use strict";n["a"]="varying vec2 v_textureCoordinates;\n\nuniform sampler2D colorTexture;\n\nconst float fxaaQualitySubpix = 0.5;\nconst float fxaaQualityEdgeThreshold = 0.125;\nconst float fxaaQualityEdgeThresholdMin = 0.0833;\n\nvoid main()\n{\n    vec2 fxaaQualityRcpFrame = vec2(1.0) / czm_viewport.zw;\n    vec4 color = FxaaPixelShader(\n        v_textureCoordinates,\n        colorTexture,\n        fxaaQualityRcpFrame,\n        fxaaQualitySubpix,\n        fxaaQualityEdgeThreshold,\n        fxaaQualityEdgeThresholdMin);\n    float alpha = texture2D(colorTexture, v_textureCoordinates).a;\n    gl_FragColor = vec4(color.rgb, alpha);\n}\n"},"1dca":function(e,n,t){"use strict";n["a"]="varying vec3 v_forwardDirectionEC;\nvarying vec3 v_texcoordNormalizationAndHalfWidth;\nvarying float v_batchId;\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#else\nvarying vec2 v_alignedPlaneDistances;\nvarying float v_texcoordT;\n#endif\n\nfloat rayPlaneDistanceUnsafe(vec3 origin, vec3 direction, vec3 planeNormal, float planeDistance) {\n    // We don't expect the ray to ever be parallel to the plane\n    return (-planeDistance - dot(planeNormal, origin)) / dot(planeNormal, direction);\n}\n\nvoid main(void)\n{\n    vec4 eyeCoordinate = gl_FragCoord;\n    eyeCoordinate /= eyeCoordinate.w;\n\n#ifdef PER_INSTANCE_COLOR\n    gl_FragColor = czm_gammaCorrect(v_color);\n#else // PER_INSTANCE_COLOR\n    // Use distances for planes aligned with segment to prevent skew in dashing\n    float distanceFromStart = rayPlaneDistanceUnsafe(eyeCoordinate.xyz, -v_forwardDirectionEC, v_forwardDirectionEC.xyz, v_alignedPlaneDistances.x);\n    float distanceFromEnd = rayPlaneDistanceUnsafe(eyeCoordinate.xyz, v_forwardDirectionEC, -v_forwardDirectionEC.xyz, v_alignedPlaneDistances.y);\n\n    // Clamp - distance to aligned planes may be negative due to mitering\n    distanceFromStart = max(0.0, distanceFromStart);\n    distanceFromEnd = max(0.0, distanceFromEnd);\n\n    float s = distanceFromStart / (distanceFromStart + distanceFromEnd);\n    s = (s * v_texcoordNormalizationAndHalfWidth.x) + v_texcoordNormalizationAndHalfWidth.y;\n\n    czm_materialInput materialInput;\n\n    materialInput.s = s;\n    materialInput.st = vec2(s, v_texcoordT);\n    materialInput.str = vec3(s, v_texcoordT, 0.0);\n\n    czm_material material = czm_getMaterial(materialInput);\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#endif // PER_INSTANCE_COLOR\n}\n"},"2a08":function(e,n,t){"use strict";n["a"]="attribute vec4 position;\n\nvarying vec3 v_outerPositionWC;\n\n#ifndef PER_FRAGMENT_ATMOSPHERE\nvarying vec3 v_mieColor;\nvarying vec3 v_rayleighColor;\n#endif\n\nvoid main(void)\n{\n    vec4 positionWC = czm_model * position;\n\n#ifndef PER_FRAGMENT_ATMOSPHERE\n    calculateMieColorAndRayleighColor(positionWC.xyz, v_mieColor, v_rayleighColor);\n#endif\n    v_outerPositionWC = positionWC.xyz;\n    gl_Position = czm_modelViewProjection * position;\n}\n"},"2b1f":function(e,n,t){"use strict";n["a"]="uniform sampler2D randomTexture;\nuniform sampler2D depthTexture;\nuniform float intensity;\nuniform float bias;\nuniform float lengthCap;\nuniform float stepSize;\nuniform float frustumLength;\n\nvarying vec2 v_textureCoordinates;\n\nvec4 clipToEye(vec2 uv, float depth)\n{\n    vec2 xy = vec2((uv.x * 2.0 - 1.0), ((1.0 - uv.y) * 2.0 - 1.0));\n    vec4 posEC = czm_inverseProjection * vec4(xy, depth, 1.0);\n    posEC = posEC / posEC.w;\n    return posEC;\n}\n\n//Reconstruct Normal Without Edge Removation\nvec3 getNormalXEdge(vec3 posInCamera, float depthU, float depthD, float depthL, float depthR, vec2 pixelSize)\n{\n    vec4 posInCameraUp = clipToEye(v_textureCoordinates - vec2(0.0, pixelSize.y), depthU);\n    vec4 posInCameraDown = clipToEye(v_textureCoordinates + vec2(0.0, pixelSize.y), depthD);\n    vec4 posInCameraLeft = clipToEye(v_textureCoordinates - vec2(pixelSize.x, 0.0), depthL);\n    vec4 posInCameraRight = clipToEye(v_textureCoordinates + vec2(pixelSize.x, 0.0), depthR);\n\n    vec3 up = posInCamera.xyz - posInCameraUp.xyz;\n    vec3 down = posInCameraDown.xyz - posInCamera.xyz;\n    vec3 left = posInCamera.xyz - posInCameraLeft.xyz;\n    vec3 right = posInCameraRight.xyz - posInCamera.xyz;\n\n    vec3 DX = length(left) < length(right) ? left : right;\n    vec3 DY = length(up) < length(down) ? up : down;\n\n    return normalize(cross(DY, DX));\n}\n\nvoid main(void)\n{\n    float depth = czm_readDepth(depthTexture, v_textureCoordinates);\n    vec4 posInCamera = clipToEye(v_textureCoordinates, depth);\n\n    if (posInCamera.z > frustumLength)\n    {\n        gl_FragColor = vec4(1.0);\n        return;\n    }\n\n    vec2 pixelSize = czm_pixelRatio / czm_viewport.zw;\n    float depthU = czm_readDepth(depthTexture, v_textureCoordinates - vec2(0.0, pixelSize.y));\n    float depthD = czm_readDepth(depthTexture, v_textureCoordinates + vec2(0.0, pixelSize.y));\n    float depthL = czm_readDepth(depthTexture, v_textureCoordinates - vec2(pixelSize.x, 0.0));\n    float depthR = czm_readDepth(depthTexture, v_textureCoordinates + vec2(pixelSize.x, 0.0));\n    vec3 normalInCamera = getNormalXEdge(posInCamera.xyz, depthU, depthD, depthL, depthR, pixelSize);\n\n    float ao = 0.0;\n    vec2 sampleDirection = vec2(1.0, 0.0);\n    float gapAngle = 90.0 * czm_radiansPerDegree;\n\n    // RandomNoise\n    float randomVal = texture2D(randomTexture, v_textureCoordinates).x;\n\n    //Loop for each direction\n    for (int i = 0; i < 4; i++)\n    {\n        float newGapAngle = gapAngle * (float(i) + randomVal);\n        float cosVal = cos(newGapAngle);\n        float sinVal = sin(newGapAngle);\n\n        //Rotate Sampling Direction\n        vec2 rotatedSampleDirection = vec2(cosVal * sampleDirection.x - sinVal * sampleDirection.y, sinVal * sampleDirection.x + cosVal * sampleDirection.y);\n        float localAO = 0.0;\n        float localStepSize = stepSize;\n\n        //Loop for each step\n        for (int j = 0; j < 6; j++)\n        {\n            vec2 newCoords = v_textureCoordinates + rotatedSampleDirection * localStepSize * pixelSize;\n\n            //Exception Handling\n            if(newCoords.x > 1.0 || newCoords.y > 1.0 || newCoords.x < 0.0 || newCoords.y < 0.0)\n            {\n                break;\n            }\n\n            float stepDepthInfo = czm_readDepth(depthTexture, newCoords);\n            vec4 stepPosInCamera = clipToEye(newCoords, stepDepthInfo);\n            vec3 diffVec = stepPosInCamera.xyz - posInCamera.xyz;\n            float len = length(diffVec);\n\n            if (len > lengthCap)\n            {\n                break;\n            }\n\n            float dotVal = clamp(dot(normalInCamera, normalize(diffVec)), 0.0, 1.0 );\n            float weight = len / lengthCap;\n            weight = 1.0 - weight * weight;\n\n            if (dotVal < bias)\n            {\n                dotVal = 0.0;\n            }\n\n            localAO = max(localAO, dotVal * weight);\n            localStepSize += stepSize;\n        }\n        ao += localAO;\n    }\n\n    ao /= 4.0;\n    ao = 1.0 - clamp(ao, 0.0, 1.0);\n    ao = pow(ao, intensity);\n    gl_FragColor = vec4(vec3(ao), 1.0);\n}\n"},"2bfd":function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform sampler2D bloomTexture;\nuniform bool glowOnly;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n\n#ifdef CZM_SELECTED_FEATURE\n    if (czm_selected()) {\n        gl_FragColor = color;\n        return;\n    }\n#endif\n\n    vec4 bloom = texture2D(bloomTexture, v_textureCoordinates);\n    gl_FragColor = glowOnly ? bloom : bloom + color;\n}\n"},"2d5d":function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform float gradations;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 rgb = texture2D(colorTexture, v_textureCoordinates).rgb;\n#ifdef CZM_SELECTED_FEATURE\n    if (czm_selected()) {\n        gl_FragColor = vec4(rgb, 1.0);\n        return;\n    }\n#endif\n    float luminance = czm_luminance(rgb);\n    float darkness = luminance * gradations;\n    darkness = (darkness - fract(darkness)) / gradations;\n    gl_FragColor = vec4(vec3(darkness), 1.0);\n}\n"},"33db":function(e,n,t){"use strict";n["a"]='attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute float batchId;\n\n#ifdef EXTRUDED_GEOMETRY\nattribute vec3 extrudeDirection;\n\nuniform float u_globeMinimumAltitude;\n#endif // EXTRUDED_GEOMETRY\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif // PER_INSTANCE_COLOR\n\n#ifdef TEXTURE_COORDINATES\n#ifdef SPHERICAL\nvarying vec4 v_sphericalExtents;\n#else // SPHERICAL\nvarying vec2 v_inversePlaneExtents;\nvarying vec4 v_westPlane;\nvarying vec4 v_southPlane;\n#endif // SPHERICAL\nvarying vec3 v_uvMinAndSphericalLongitudeRotation;\nvarying vec3 v_uMaxAndInverseDistance;\nvarying vec3 v_vMaxAndInverseDistance;\n#endif // TEXTURE_COORDINATES\n\nvoid main()\n{\n    vec4 position = czm_computePosition();\n\n#ifdef EXTRUDED_GEOMETRY\n    float delta = min(u_globeMinimumAltitude, czm_geometricToleranceOverMeter * length(position.xyz));\n    delta *= czm_sceneMode == czm_sceneMode3D ? 1.0 : 0.0;\n\n    //extrudeDirection is zero for the top layer\n    position = position + vec4(extrudeDirection * delta, 0.0);\n#endif\n\n#ifdef TEXTURE_COORDINATES\n#ifdef SPHERICAL\n    v_sphericalExtents = czm_batchTable_sphericalExtents(batchId);\n    v_uvMinAndSphericalLongitudeRotation.z = czm_batchTable_longitudeRotation(batchId);\n#else // SPHERICAL\n#ifdef COLUMBUS_VIEW_2D\n    vec4 planes2D_high = czm_batchTable_planes2D_HIGH(batchId);\n    vec4 planes2D_low = czm_batchTable_planes2D_LOW(batchId);\n\n    // If the primitive is split across the IDL (planes2D_high.x > planes2D_high.w):\n    // - If this vertex is on the east side of the IDL (position3DLow.y > 0.0, comparison with position3DHigh may produce artifacts)\n    // - existing "east" is on the wrong side of the world, far away (planes2D_high/low.w)\n    // - so set "east" as beyond the eastmost extent of the projection (idlSplitNewPlaneHiLow)\n    vec2 idlSplitNewPlaneHiLow = vec2(EAST_MOST_X_HIGH - (WEST_MOST_X_HIGH - planes2D_high.w), EAST_MOST_X_LOW - (WEST_MOST_X_LOW - planes2D_low.w));\n    bool idlSplit = planes2D_high.x > planes2D_high.w && position3DLow.y > 0.0;\n    planes2D_high.w = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.x, planes2D_high.w);\n    planes2D_low.w = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.y, planes2D_low.w);\n\n    // - else, if this vertex is on the west side of the IDL (position3DLow.y < 0.0)\n    // - existing "west" is on the wrong side of the world, far away (planes2D_high/low.x)\n    // - so set "west" as beyond the westmost extent of the projection (idlSplitNewPlaneHiLow)\n    idlSplit = planes2D_high.x > planes2D_high.w && position3DLow.y < 0.0;\n    idlSplitNewPlaneHiLow = vec2(WEST_MOST_X_HIGH - (EAST_MOST_X_HIGH - planes2D_high.x), WEST_MOST_X_LOW - (EAST_MOST_X_LOW - planes2D_low.x));\n    planes2D_high.x = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.x, planes2D_high.x);\n    planes2D_low.x = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.y, planes2D_low.x);\n\n    vec3 southWestCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, planes2D_high.xy), vec3(0.0, planes2D_low.xy))).xyz;\n    vec3 northWestCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, planes2D_high.x, planes2D_high.z), vec3(0.0, planes2D_low.x, planes2D_low.z))).xyz;\n    vec3 southEastCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, planes2D_high.w, planes2D_high.y), vec3(0.0, planes2D_low.w, planes2D_low.y))).xyz;\n#else // COLUMBUS_VIEW_2D\n    // 3D case has smaller "plane extents," so planes encoded as a 64 bit position and 2 vec3s for distances/direction\n    vec3 southWestCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(czm_batchTable_southWest_HIGH(batchId), czm_batchTable_southWest_LOW(batchId))).xyz;\n    vec3 northWestCorner = czm_normal * czm_batchTable_northward(batchId) + southWestCorner;\n    vec3 southEastCorner = czm_normal * czm_batchTable_eastward(batchId) + southWestCorner;\n#endif // COLUMBUS_VIEW_2D\n\n    vec3 eastWard = southEastCorner - southWestCorner;\n    float eastExtent = length(eastWard);\n    eastWard /= eastExtent;\n\n    vec3 northWard = northWestCorner - southWestCorner;\n    float northExtent = length(northWard);\n    northWard /= northExtent;\n\n    v_westPlane = vec4(eastWard, -dot(eastWard, southWestCorner));\n    v_southPlane = vec4(northWard, -dot(northWard, southWestCorner));\n    v_inversePlaneExtents = vec2(1.0 / eastExtent, 1.0 / northExtent);\n#endif // SPHERICAL\n    vec4 uvMinAndExtents = czm_batchTable_uvMinAndExtents(batchId);\n    vec4 uMaxVmax = czm_batchTable_uMaxVmax(batchId);\n\n    v_uMaxAndInverseDistance = vec3(uMaxVmax.xy, uvMinAndExtents.z);\n    v_vMaxAndInverseDistance = vec3(uMaxVmax.zw, uvMinAndExtents.w);\n    v_uvMinAndSphericalLongitudeRotation.xy = uvMinAndExtents.xy;\n#endif // TEXTURE_COORDINATES\n\n#ifdef PER_INSTANCE_COLOR\n    v_color = czm_batchTable_color(batchId);\n#endif\n\n    gl_Position = czm_depthClamp(czm_modelViewProjectionRelativeToEye * position);\n}\n'},"34e1":function(e,n,t){"use strict";n["a"]='uniform sampler2D colorTexture;\n\nuniform float avgLuminance;\nuniform float threshold;\nuniform float offset;\n\nvarying vec2 v_textureCoordinates;\n\nfloat key(float avg)\n{\n    float guess = 1.5 - (1.5 / (avg * 0.1 + 1.0));\n    return max(0.0, guess) + 0.1;\n}\n\n// See section 9. "The bright-pass filter" of Realtime HDR Rendering\n// http://www.cg.tuwien.ac.at/research/publications/2007/Luksch_2007_RHR/Luksch_2007_RHR-RealtimeHDR%20.pdf\n\nvoid main()\n{\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n    vec3 xyz = czm_RGBToXYZ(color.rgb);\n    float luminance = xyz.r;\n\n    float scaledLum = key(avgLuminance) * luminance / avgLuminance;\n    float brightLum = max(scaledLum - threshold, 0.0);\n    float brightness = brightLum / (offset + brightLum);\n\n    xyz.r = brightness;\n    gl_FragColor = vec4(czm_XYZToRGB(xyz), 1.0);\n}\n'},3573:function(e,n,t){"use strict";n["a"]="uniform sampler2D depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    float depth = czm_readDepth(depthTexture, v_textureCoordinates);\n    gl_FragColor = vec4(vec3(depth), 1.0);\n}\n"},3720:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = texture2D(colorTexture, v_textureCoordinates);\n}\n"},4720:function(e,n,t){"use strict";n["a"]="uniform sampler2D u_depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    float z_window = czm_unpackDepth(texture2D(u_depthTexture, v_textureCoordinates));\n    z_window = czm_reverseLogDepth(z_window);\n    float n_range = czm_depthRange.near;\n    float f_range = czm_depthRange.far;\n    float z_ndc = (2.0 * z_window - n_range - f_range) / (f_range - n_range);\n    float scale = pow(z_ndc * 0.5 + 0.5, 8.0);\n    gl_FragColor = vec4(mix(vec3(0.0), vec3(1.0), scale), 1.0);\n}\n"},"609e":function(e,n,t){"use strict";n["a"]="varying vec4 v_color;\nvarying vec4 v_outlineColor;\nvarying float v_innerPercent;\nvarying float v_pixelDistance;\nvarying vec4 v_pickColor;\n\nvoid main()\n{\n    // The distance in UV space from this fragment to the center of the point, at most 0.5.\n    float distanceToCenter = length(gl_PointCoord - vec2(0.5));\n    // The max distance stops one pixel shy of the edge to leave space for anti-aliasing.\n    float maxDistance = max(0.0, 0.5 - v_pixelDistance);\n    float wholeAlpha = 1.0 - smoothstep(maxDistance, 0.5, distanceToCenter);\n    float innerAlpha = 1.0 - smoothstep(maxDistance * v_innerPercent, 0.5 * v_innerPercent, distanceToCenter);\n\n    vec4 color = mix(v_outlineColor, v_color, innerAlpha);\n    color.a *= wholeAlpha;\n\n// Fully transparent parts of the billboard are not pickable.\n#if !defined(OPAQUE) && !defined(TRANSLUCENT)\n    if (color.a < 0.005)   // matches 0/255 and 1/255\n    {\n        discard;\n    }\n#else\n// The billboard is rendered twice. The opaque pass discards translucent fragments\n// and the translucent pass discards opaque fragments.\n#ifdef OPAQUE\n    if (color.a < 0.995)   // matches < 254/255\n    {\n        discard;\n    }\n#else\n    if (color.a >= 0.995)  // matches 254/255 and 255/255\n    {\n        discard;\n    }\n#endif\n#endif\n\n    gl_FragColor = czm_gammaCorrect(color);\n    czm_writeLogDepth();\n}\n"},6448:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform sampler2D silhouetteTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec4 silhouetteColor = texture2D(silhouetteTexture, v_textureCoordinates);\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n    gl_FragColor = mix(color, silhouetteColor, silhouetteColor.a);\n}\n"},6768:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform sampler2D blurTexture;\nuniform sampler2D depthTexture;\nuniform float focalDistance;\n\nvarying vec2 v_textureCoordinates;\n\nvec4 toEye(vec2 uv, float depth)\n{\n   vec2 xy = vec2((uv.x * 2.0 - 1.0), ((1.0 - uv.y) * 2.0 - 1.0));\n   vec4 posInCamera = czm_inverseProjection * vec4(xy, depth, 1.0);\n   posInCamera = posInCamera / posInCamera.w;\n   return posInCamera;\n}\n\nfloat computeDepthBlur(float depth)\n{\n    float f;\n    if (depth < focalDistance)\n    {\n        f = (focalDistance - depth) / (focalDistance - czm_currentFrustum.x);\n    }\n    else\n    {\n        f = (depth - focalDistance) / (czm_currentFrustum.y - focalDistance);\n        f = pow(f, 0.1);\n    }\n    f *= f;\n    f = clamp(f, 0.0, 1.0);\n    return pow(f, 0.5);\n}\n\nvoid main(void)\n{\n    float depth = czm_readDepth(depthTexture, v_textureCoordinates);\n    vec4 posInCamera = toEye(v_textureCoordinates, depth);\n    float d = computeDepthBlur(-posInCamera.z);\n    gl_FragColor = mix(texture2D(colorTexture, v_textureCoordinates), texture2D(blurTexture, v_textureCoordinates), d);\n}\n"},"688e":function(e,n,t){"use strict";n["a"]="attribute vec3 position;\n\nvarying vec3 v_texCoord;\n\nvoid main()\n{\n    vec3 p = czm_viewRotation * (czm_temeToPseudoFixed * (czm_entireFrustum.y * position));\n    gl_Position = czm_projection * vec4(p, 1.0);\n    v_texCoord = position.xyz;\n}\n"},"6bd8":function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\n\n#ifdef DEBUG_SHOW_DEPTH\nuniform sampler2D u_packedTranslucentDepth;\n#endif\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n#ifdef DEBUG_SHOW_DEPTH\n    if (v_textureCoordinates.x < 0.5)\n    {\n        gl_FragColor.rgb = vec3(czm_unpackDepth(texture2D(u_packedTranslucentDepth, v_textureCoordinates)));\n        gl_FragColor.a = 1.0;\n    }\n#else\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n\n#ifdef PICK\n    if (color == vec4(0.0))\n    {\n        discard;\n    }\n#else\n    // Reverse premultiplication process to get the correct composited result of the classification primitives\n    color.rgb /= color.a;\n#endif\n    gl_FragColor = color;\n#endif\n}\n"},7027:function(e,n,t){"use strict";n["a"]="uniform sampler2D u_texture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = texture2D(u_texture, v_textureCoordinates);\n}\n"},"7ae0":function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform sampler2D ambientOcclusionTexture;\nuniform bool ambientOcclusionOnly;\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 color = texture2D(colorTexture, v_textureCoordinates).rgb;\n    vec3 ao = texture2D(ambientOcclusionTexture, v_textureCoordinates).rgb;\n    gl_FragColor.rgb = ambientOcclusionOnly ? ao : ao * color;\n}\n"},"7e2c":function(e,n,t){"use strict";n["a"]="uniform sampler2D depthTexture;\nuniform float length;\nuniform vec4 color;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    float directions[3];\n    directions[0] = -1.0;\n    directions[1] = 0.0;\n    directions[2] = 1.0;\n\n    float scalars[3];\n    scalars[0] = 3.0;\n    scalars[1] = 10.0;\n    scalars[2] = 3.0;\n\n    float padx = czm_pixelRatio / czm_viewport.z;\n    float pady = czm_pixelRatio / czm_viewport.w;\n\n#ifdef CZM_SELECTED_FEATURE\n    bool selected = false;\n    for (int i = 0; i < 3; ++i)\n    {\n        float dir = directions[i];\n        selected = selected || czm_selected(vec2(-padx, dir * pady));\n        selected = selected || czm_selected(vec2(padx, dir * pady));\n        selected = selected || czm_selected(vec2(dir * padx, -pady));\n        selected = selected || czm_selected(vec2(dir * padx, pady));\n        if (selected)\n        {\n            break;\n        }\n    }\n    if (!selected)\n    {\n        gl_FragColor = vec4(color.rgb, 0.0);\n        return;\n    }\n#endif\n\n    float horizEdge = 0.0;\n    float vertEdge = 0.0;\n\n    for (int i = 0; i < 3; ++i)\n    {\n        float dir = directions[i];\n        float scale = scalars[i];\n\n        horizEdge -= texture2D(depthTexture, v_textureCoordinates + vec2(-padx, dir * pady)).x * scale;\n        horizEdge += texture2D(depthTexture, v_textureCoordinates + vec2(padx, dir * pady)).x * scale;\n\n        vertEdge -= texture2D(depthTexture, v_textureCoordinates + vec2(dir * padx, -pady)).x * scale;\n        vertEdge += texture2D(depthTexture, v_textureCoordinates + vec2(dir * padx, pady)).x * scale;\n    }\n\n    float len = sqrt(horizEdge * horizEdge + vertEdge * vertEdge);\n    gl_FragColor = vec4(color.rgb, len > length ? color.a : 0.0);\n}\n"},8167:function(e,n,t){"use strict";n["a"]="uniform samplerCube u_cubeMap;\n\nvarying vec3 v_texCoord;\n\nvoid main()\n{\n    vec4 color = textureCube(u_cubeMap, normalize(v_texCoord));\n    gl_FragColor = vec4(czm_gammaCorrect(color).rgb, czm_morphTime);\n}\n"},"8a4d":function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform float contrast;\nuniform float brightness;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 sceneColor = texture2D(colorTexture, v_textureCoordinates).xyz;\n    sceneColor = czm_RGBToHSB(sceneColor);\n    sceneColor.z += brightness;\n    sceneColor = czm_HSBToRGB(sceneColor);\n\n    float factor = (259.0 * (contrast + 255.0)) / (255.0 * (259.0 - contrast));\n    sceneColor = factor * (sceneColor - vec3(0.5)) + vec3(0.5);\n    gl_FragColor = vec4(sceneColor, 1.0);\n}\n"},"8c6d":function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n\n#ifdef AUTO_EXPOSURE\n    color /= texture2D(autoExposure, vec2(0.5)).r;\n#endif\n    color = czm_acesTonemapping(color);\n    color = czm_inverseGamma(color);\n\n    gl_FragColor = vec4(color, fragmentColor.a);\n}\n"},"987b":function(e,n,t){"use strict";n["a"]="uniform highp sampler2D u_depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = czm_packDepth(texture2D(u_depthTexture, v_textureCoordinates).r);\n}\n"},"9d1c":function(e,n,t){"use strict";n["a"]='#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n\nvarying vec4 v_startPlaneNormalEcAndHalfWidth;\nvarying vec4 v_endPlaneNormalEcAndBatchId;\nvarying vec4 v_rightPlaneEC; // Technically can compute distance for this here\nvarying vec4 v_endEcAndStartEcX;\nvarying vec4 v_texcoordNormalizationAndStartEcYZ;\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif\n\nvoid main(void)\n{\n    float logDepthOrDepth = czm_branchFreeTernary(czm_sceneMode == czm_sceneMode2D, gl_FragCoord.z, czm_unpackDepth(texture2D(czm_globeDepthTexture, gl_FragCoord.xy / czm_viewport.zw)));\n    vec3 ecStart = vec3(v_endEcAndStartEcX.w, v_texcoordNormalizationAndStartEcYZ.zw);\n\n    // Discard for sky\n    if (logDepthOrDepth == 0.0) {\n#ifdef DEBUG_SHOW_VOLUME\n        gl_FragColor = vec4(1.0, 0.0, 0.0, 0.5);\n        return;\n#else // DEBUG_SHOW_VOLUME\n        discard;\n#endif // DEBUG_SHOW_VOLUME\n    }\n\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, logDepthOrDepth);\n    eyeCoordinate /= eyeCoordinate.w;\n\n    float halfMaxWidth = v_startPlaneNormalEcAndHalfWidth.w * czm_metersPerPixel(eyeCoordinate);\n    // Check distance of the eye coordinate against the right-facing plane\n    float widthwiseDistance = czm_planeDistance(v_rightPlaneEC, eyeCoordinate.xyz);\n\n    // Check eye coordinate against the mitering planes\n    float distanceFromStart = czm_planeDistance(v_startPlaneNormalEcAndHalfWidth.xyz, -dot(ecStart, v_startPlaneNormalEcAndHalfWidth.xyz), eyeCoordinate.xyz);\n    float distanceFromEnd = czm_planeDistance(v_endPlaneNormalEcAndBatchId.xyz, -dot(v_endEcAndStartEcX.xyz, v_endPlaneNormalEcAndBatchId.xyz), eyeCoordinate.xyz);\n\n    if (abs(widthwiseDistance) > halfMaxWidth || distanceFromStart < 0.0 || distanceFromEnd < 0.0) {\n#ifdef DEBUG_SHOW_VOLUME\n        gl_FragColor = vec4(1.0, 0.0, 0.0, 0.5);\n        return;\n#else // DEBUG_SHOW_VOLUME\n        discard;\n#endif // DEBUG_SHOW_VOLUME\n    }\n\n    // Check distance of the eye coordinate against start and end planes with normals in the right plane.\n    // For computing unskewed lengthwise texture coordinate.\n    // Can also be used for clipping extremely pointy miters, but in practice unnecessary because of miter breaking.\n\n    // aligned plane: cross the right plane normal with miter plane normal, then cross the result with right again to point it more "forward"\n    vec3 alignedPlaneNormal;\n\n    // start aligned plane\n    alignedPlaneNormal = cross(v_rightPlaneEC.xyz, v_startPlaneNormalEcAndHalfWidth.xyz);\n    alignedPlaneNormal = normalize(cross(alignedPlaneNormal, v_rightPlaneEC.xyz));\n    distanceFromStart = czm_planeDistance(alignedPlaneNormal, -dot(alignedPlaneNormal, ecStart), eyeCoordinate.xyz);\n\n    // end aligned plane\n    alignedPlaneNormal = cross(v_rightPlaneEC.xyz, v_endPlaneNormalEcAndBatchId.xyz);\n    alignedPlaneNormal = normalize(cross(alignedPlaneNormal, v_rightPlaneEC.xyz));\n    distanceFromEnd = czm_planeDistance(alignedPlaneNormal, -dot(alignedPlaneNormal, v_endEcAndStartEcX.xyz), eyeCoordinate.xyz);\n\n#ifdef PER_INSTANCE_COLOR\n    gl_FragColor = czm_gammaCorrect(v_color);\n#else // PER_INSTANCE_COLOR\n    // Clamp - distance to aligned planes may be negative due to mitering,\n    // so fragment texture coordinate might be out-of-bounds.\n    float s = clamp(distanceFromStart / (distanceFromStart + distanceFromEnd), 0.0, 1.0);\n    s = (s * v_texcoordNormalizationAndStartEcYZ.x) + v_texcoordNormalizationAndStartEcYZ.y;\n    float t = (widthwiseDistance + halfMaxWidth) / (2.0 * halfMaxWidth);\n\n    czm_materialInput materialInput;\n\n    materialInput.s = s;\n    materialInput.st = vec2(s, t);\n    materialInput.str = vec3(s, t, 0.0);\n\n    czm_material material = czm_getMaterial(materialInput);\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#endif // PER_INSTANCE_COLOR\n\n    // Premultiply alpha. Required for classification primitives on translucent globe.\n    gl_FragColor.rgb *= gl_FragColor.a;\n\n    czm_writeDepthClamp();\n}\n'},a415:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\n// See slides 142 and 143:\n//     http://www.gdcvault.com/play/1012459/Uncharted_2__HDR_Lighting\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n\n#ifdef AUTO_EXPOSURE\n    float exposure = texture2D(autoExposure, vec2(0.5)).r;\n    color /= exposure;\n#endif\n\n\tconst float A = 0.22; // shoulder strength\n\tconst float B = 0.30; // linear strength\n\tconst float C = 0.10; // linear angle\n\tconst float D = 0.20; // toe strength\n\tconst float E = 0.01; // toe numerator\n\tconst float F = 0.30; // toe denominator\n\n\tconst float white = 11.2; // linear white point value\n\n\tvec3 c = ((color * (A * color + C * B) + D * E) / (color * ( A * color + B) + D * F)) - E / F;\n\tfloat w = ((white * (A * white + C * B) + D * E) / (white * ( A * white + B) + D * F)) - E / F;\n\n\tc = czm_inverseGamma(c / w);\n\tgl_FragColor = vec4(c, fragmentColor.a);\n}\n"},a48a:function(e,n,t){"use strict";n["a"]='uniform float u_maxTotalPointSize;\n\nattribute vec4 positionHighAndSize;\nattribute vec4 positionLowAndOutline;\nattribute vec4 compressedAttribute0;                       // color, outlineColor, pick color\nattribute vec4 compressedAttribute1;                       // show, translucency by distance, some free space\nattribute vec4 scaleByDistance;                            // near, nearScale, far, farScale\nattribute vec3 distanceDisplayConditionAndDisableDepth;    // near, far, disableDepthTestDistance\n\nvarying vec4 v_color;\nvarying vec4 v_outlineColor;\nvarying float v_innerPercent;\nvarying float v_pixelDistance;\nvarying vec4 v_pickColor;\n\nconst float SHIFT_LEFT8 = 256.0;\nconst float SHIFT_RIGHT8 = 1.0 / 256.0;\n\nvoid main()\n{\n    // Modifying this shader may also require modifications to PointPrimitive._computeScreenSpacePosition\n\n    // unpack attributes\n    vec3 positionHigh = positionHighAndSize.xyz;\n    vec3 positionLow = positionLowAndOutline.xyz;\n    float outlineWidthBothSides = 2.0 * positionLowAndOutline.w;\n    float totalSize = positionHighAndSize.w + outlineWidthBothSides;\n    float outlinePercent = outlineWidthBothSides / totalSize;\n    // Scale in response to browser-zoom.\n    totalSize *= czm_pixelRatio;\n    // Add padding for anti-aliasing on both sides.\n    totalSize += 3.0;\n\n    float temp = compressedAttribute1.x * SHIFT_RIGHT8;\n    float show = floor(temp);\n\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    vec4 translucencyByDistance;\n    translucencyByDistance.x = compressedAttribute1.z;\n    translucencyByDistance.z = compressedAttribute1.w;\n\n    translucencyByDistance.y = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n\n    temp = compressedAttribute1.y * SHIFT_RIGHT8;\n    translucencyByDistance.w = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n#endif\n\n    ///////////////////////////////////////////////////////////////////////////\n\n    vec4 color;\n    vec4 outlineColor;\n    vec4 pickColor;\n\n    // compressedAttribute0.z => pickColor.rgb\n\n    temp = compressedAttribute0.z * SHIFT_RIGHT8;\n    pickColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    pickColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor.r = floor(temp);\n\n    // compressedAttribute0.x => color.rgb\n\n    temp = compressedAttribute0.x * SHIFT_RIGHT8;\n    color.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    color.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    color.r = floor(temp);\n\n    // compressedAttribute0.y => outlineColor.rgb\n\n    temp = compressedAttribute0.y * SHIFT_RIGHT8;\n    outlineColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor.r = floor(temp);\n\n    // compressedAttribute0.w => color.a, outlineColor.a, pickColor.a\n\n    temp = compressedAttribute0.w * SHIFT_RIGHT8;\n    pickColor.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor = pickColor / 255.0;\n\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineColor.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor /= 255.0;\n    color.a = floor(temp);\n    color /= 255.0;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n    vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n    vec4 positionEC = czm_modelViewRelativeToEye * p;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n#if defined(EYE_DISTANCE_SCALING) || defined(EYE_DISTANCE_TRANSLUCENCY) || defined(DISTANCE_DISPLAY_CONDITION) || defined(DISABLE_DEPTH_DISTANCE)\n    float lengthSq;\n    if (czm_sceneMode == czm_sceneMode2D)\n    {\n        // 2D camera distance is a special case\n        // treat all billboards as flattened to the z=0.0 plane\n        lengthSq = czm_eyeHeight2D.y;\n    }\n    else\n    {\n        lengthSq = dot(positionEC.xyz, positionEC.xyz);\n    }\n#endif\n\n#ifdef EYE_DISTANCE_SCALING\n    totalSize *= czm_nearFarScalar(scaleByDistance, lengthSq);\n#endif\n    // Clamp to max point size.\n    totalSize = min(totalSize, u_maxTotalPointSize);\n    // If size is too small, push vertex behind near plane for clipping.\n    // Note that context.minimumAliasedPointSize "will be at most 1.0".\n    if (totalSize < 1.0)\n    {\n        positionEC.xyz = vec3(0.0);\n        totalSize = 1.0;\n    }\n\n    float translucency = 1.0;\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    translucency = czm_nearFarScalar(translucencyByDistance, lengthSq);\n    // push vertex behind near plane for clipping\n    if (translucency < 0.004)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n#ifdef DISTANCE_DISPLAY_CONDITION\n    float nearSq = distanceDisplayConditionAndDisableDepth.x;\n    float farSq = distanceDisplayConditionAndDisableDepth.y;\n    if (lengthSq < nearSq || lengthSq > farSq) {\n        // push vertex behind camera to force it to be clipped\n        positionEC.xyz = vec3(0.0, 0.0, 1.0);\n    }\n#endif\n\n    gl_Position = czm_projection * positionEC;\n    czm_vertexLogDepth();\n\n#ifdef DISABLE_DEPTH_DISTANCE\n    float disableDepthTestDistance = distanceDisplayConditionAndDisableDepth.z;\n    if (disableDepthTestDistance == 0.0 && czm_minimumDisableDepthTestDistance != 0.0)\n    {\n        disableDepthTestDistance = czm_minimumDisableDepthTestDistance;\n    }\n\n    if (disableDepthTestDistance != 0.0)\n    {\n        // Don\'t try to "multiply both sides" by w.  Greater/less-than comparisons won\'t work for negative values of w.\n        float zclip = gl_Position.z / gl_Position.w;\n        bool clipped = (zclip < -1.0 || zclip > 1.0);\n        if (!clipped && (disableDepthTestDistance < 0.0 || (lengthSq > 0.0 && lengthSq < disableDepthTestDistance)))\n        {\n            // Position z on the near plane.\n            gl_Position.z = -gl_Position.w;\n#ifdef LOG_DEPTH\n            czm_vertexLogDepth(vec4(czm_currentFrustum.x));\n#endif\n        }\n    }\n#endif\n\n    v_color = color;\n    v_color.a *= translucency * show;\n    v_outlineColor = outlineColor;\n    v_outlineColor.a *= translucency * show;\n\n    v_innerPercent = 1.0 - outlinePercent;\n    v_pixelDistance = 2.0 / totalSize;\n    gl_PointSize = totalSize * show;\n    gl_Position *= show;\n\n    v_pickColor = pickColor;\n}\n'},aab0:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform vec3 white;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\n// See equation 4:\n//    http://www.cs.utah.edu/~reinhard/cdrom/tonemap.pdf\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n#ifdef AUTO_EXPOSURE\n    float exposure = texture2D(autoExposure, vec2(0.5)).r;\n    color /= exposure;\n#endif\n    color = (color * (1.0 + color / white)) / (1.0 + color);\n    color = czm_inverseGamma(color);\n    gl_FragColor = vec4(color, fragmentColor.a);\n}\n"},ae16:function(e,n,t){"use strict";n["a"]="#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n\n#ifdef VECTOR_TILE\nuniform vec4 u_highlightColor;\n#endif\n\nvoid main(void)\n{\n#ifdef VECTOR_TILE\n    gl_FragColor = czm_gammaCorrect(u_highlightColor);\n#else\n    gl_FragColor = vec4(1.0);\n#endif\n    czm_writeDepthClamp();\n}\n"},ae18:function(e,n,t){"use strict";n["a"]="#define SAMPLES 8\n\nuniform float delta;\nuniform float sigma;\nuniform float direction; // 0.0 for x direction, 1.0 for y direction\n\nuniform sampler2D colorTexture;\n\n#ifdef USE_STEP_SIZE\nuniform float stepSize;\n#else\nuniform vec2 step;\n#endif\n\nvarying vec2 v_textureCoordinates;\n\n//  Incremental Computation of the Gaussian:\n//  https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch40.html\n\nvoid main()\n{\n    vec2 st = v_textureCoordinates;\n    vec2 dir = vec2(1.0 - direction, direction);\n\n#ifdef USE_STEP_SIZE\n    vec2 step = vec2(stepSize * (czm_pixelRatio / czm_viewport.zw));\n#else\n    vec2 step = step;\n#endif\n\n    vec3 g;\n    g.x = 1.0 / (sqrt(czm_twoPi) * sigma);\n    g.y = exp((-0.5 * delta * delta) / (sigma * sigma));\n    g.z = g.y * g.y;\n\n    vec4 result = texture2D(colorTexture, st) * g.x;\n    for (int i = 1; i < SAMPLES; ++i)\n    {\n        g.xy *= g.yz;\n\n        vec2 offset = float(i) * dir * step;\n        result += texture2D(colorTexture, st - offset) * g.x;\n        result += texture2D(colorTexture, st + offset) * g.x;\n    }\n\n    gl_FragColor = result;\n}\n"},aeca:function(e,n,t){"use strict";
/**
 * @license
 * Copyright (c) 2000-2005, Sean O'Neil (s_p_oneil@hotmail.com)
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * * Redistributions of source code must retain the above copyright notice,
 *   this list of conditions and the following disclaimer.
 * * Redistributions in binary form must reproduce the above copyright notice,
 *   this list of conditions and the following disclaimer in the documentation
 *   and/or other materials provided with the distribution.
 * * Neither the name of the project nor the names of its contributors may be
 *   used to endorse or promote products derived from this software without
 *   specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * Modifications made by Cesium GS, Inc.
 */n["a"]="/**\n * @license\n * Copyright (c) 2000-2005, Sean O'Neil (s_p_oneil@hotmail.com)\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n * * Redistributions of source code must retain the above copyright notice,\n *   this list of conditions and the following disclaimer.\n * * Redistributions in binary form must reproduce the above copyright notice,\n *   this list of conditions and the following disclaimer in the documentation\n *   and/or other materials provided with the distribution.\n * * Neither the name of the project nor the names of its contributors may be\n *   used to endorse or promote products derived from this software without\n *   specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * Modifications made by Cesium GS, Inc.\n */\n\n // Code:  http://sponeil.net/\n // GPU Gems 2 Article:  https://developer.nvidia.com/gpugems/GPUGems2/gpugems2_chapter16.html\n\nconst float Kr = 0.0025;\nconst float Kr4PI = Kr * 4.0 * czm_pi;\nconst float Km = 0.0015;\nconst float Km4PI = Km * 4.0 * czm_pi;\nconst float ESun = 15.0;\nconst float KmESun = Km * ESun;\nconst float KrESun = Kr * ESun;\nconst vec3 InvWavelength = vec3(\n    5.60204474633241,  // Red = 1.0 / Math.pow(0.650, 4.0)\n    9.473284437923038, // Green = 1.0 / Math.pow(0.570, 4.0)\n    19.643802610477206); // Blue = 1.0 / Math.pow(0.475, 4.0)\nconst float rayleighScaleDepth = 0.25;\n\nconst int nSamples = 2;\nconst float fSamples = 2.0;\n\nconst float g = -0.95;\nconst float g2 = g * g;\n\n#ifdef COLOR_CORRECT\nuniform vec3 u_hsbShift; // Hue, saturation, brightness\n#endif\n\nuniform vec3 u_radiiAndDynamicAtmosphereColor; // outer radius, inner radius, dynamic atmosphere color flag\n\nfloat scale(float cosAngle)\n{\n    float x = 1.0 - cosAngle;\n    return rayleighScaleDepth  * exp(-0.00287 + x*(0.459 + x*(3.83 + x*(-6.80 + x*5.25))));\n}\n\nvec3 getLightDirection(vec3 positionWC)\n{\n    float lightEnum = u_radiiAndDynamicAtmosphereColor.z;\n    vec3 lightDirection =\n        positionWC * float(lightEnum == 0.0) +\n        czm_lightDirectionWC * float(lightEnum == 1.0) +\n        czm_sunDirectionWC * float(lightEnum == 2.0);\n    return normalize(lightDirection);\n}\n\nvoid calculateRayScatteringFromSpace(in vec3 positionWC, in vec3 ray, in float innerRadius, in float outerRadius, inout float far, out vec3 start, out float startOffset)\n{\n    // Calculate the closest intersection of the ray with the outer atmosphere (which is the near point of the ray passing through the atmosphere)\n    float cameraHeight = length(positionWC);\n    float B = 2.0 * dot(positionWC, ray);\n    float C = cameraHeight * cameraHeight - outerRadius * outerRadius;\n    float det = max(0.0, B * B - 4.0 * C);\n    float near = 0.5 * (-B - sqrt(det));\n\n    // Calculate the ray's starting position, then calculate its scattering offset\n    start = positionWC + ray * near;\n    far -= near;\n    float startAngle = dot(ray, start) / outerRadius;\n    float startDepth = exp(-1.0 / rayleighScaleDepth);\n    startOffset = startDepth * scale(startAngle);\n}\n\nvoid calculateRayScatteringFromGround(in vec3 positionWC, in vec3 ray, in float atmosphereScale, in float innerRadius, out vec3 start, out float startOffset)\n{\n    // Calculate the ray's starting position, then calculate its scattering offset\n    float cameraHeight = length(positionWC);\n    start = positionWC;\n    float height = length(start);\n    float depth = exp((atmosphereScale / rayleighScaleDepth ) * (innerRadius - cameraHeight));\n    float startAngle = dot(ray, start) / height;\n    startOffset = depth*scale(startAngle);\n}\n\nczm_raySegment rayEllipsoidIntersection(czm_ray ray, vec3 inverseRadii)\n{\n    vec3 o = inverseRadii * (czm_inverseView * vec4(ray.origin, 1.0)).xyz;\n    vec3 d = inverseRadii * (czm_inverseView * vec4(ray.direction, 0.0)).xyz;\n\n    float a = dot(d, d);\n    float b = dot(d, o);\n    float c = dot(o, o) - 1.0;\n    float discriminant = b * b - a * c;\n    if (discriminant < 0.0)\n    {\n        return czm_emptyRaySegment;\n    }\n    discriminant = sqrt(discriminant);\n    float t1 = (-b - discriminant) / a;\n    float t2 = (-b + discriminant) / a;\n\n    if (t1 < 0.0 && t2 < 0.0)\n    {\n        return czm_emptyRaySegment;\n    }\n\n    if (t1 < 0.0 && t2 >= 0.0)\n    {\n        t1 = 0.0;\n    }\n\n    return czm_raySegment(t1, t2);\n}\n\nvec3 getAdjustedPosition(vec3 positionWC, float innerRadius)\n{\n  // Adjust the camera position so that atmosphere color looks the same wherever the eye height is the same\n  float cameraHeight = czm_eyeHeight + innerRadius;\n  return normalize(positionWC) * cameraHeight;\n}\n\nvec3 getTranslucentPosition(vec3 positionWC, vec3 outerPositionWC, float innerRadius, out bool intersectsEllipsoid)\n{\n    vec3 directionWC = normalize(outerPositionWC - positionWC);\n    vec3 directionEC = czm_viewRotation * directionWC;\n    czm_ray viewRay = czm_ray(vec3(0.0), directionEC);\n    czm_raySegment raySegment = rayEllipsoidIntersection(viewRay, czm_ellipsoidInverseRadii);\n    intersectsEllipsoid = raySegment.start >= 0.0;\n\n    if (intersectsEllipsoid)\n    {\n        return positionWC + raySegment.stop * directionWC;\n    }\n\n    return getAdjustedPosition(positionWC, innerRadius);\n}\n\nvoid calculateMieColorAndRayleighColor(vec3 outerPositionWC, out vec3 mieColor, out vec3 rayleighColor)\n{\n    // Unpack attributes\n    float outerRadius = u_radiiAndDynamicAtmosphereColor.x;\n    float innerRadius = u_radiiAndDynamicAtmosphereColor.y;\n\n#ifdef GLOBE_TRANSLUCENT\n    bool intersectsEllipsoid = false;\n    vec3 startPositionWC = getTranslucentPosition(czm_viewerPositionWC, outerPositionWC, innerRadius, intersectsEllipsoid);\n#else\n    vec3 startPositionWC = getAdjustedPosition(czm_viewerPositionWC, innerRadius);\n#endif\n\n    vec3 lightDirection = getLightDirection(startPositionWC);\n\n    // Get the ray from the start position to the outer position and its length (which is the far point of the ray passing through the atmosphere)\n    vec3 ray = outerPositionWC - startPositionWC;\n    float far = length(ray);\n    ray /= far;\n\n    float atmosphereScale = 1.0 / (outerRadius - innerRadius);\n\n    vec3 start;\n    float startOffset;\n\n#ifdef SKY_FROM_SPACE\n#ifdef GLOBE_TRANSLUCENT\n    if (intersectsEllipsoid)\n    {\n        calculateRayScatteringFromGround(startPositionWC, ray, atmosphereScale, innerRadius, start, startOffset);\n    }\n    else\n    {\n        calculateRayScatteringFromSpace(startPositionWC, ray, innerRadius, outerRadius, far, start, startOffset);\n    }\n#else\n    calculateRayScatteringFromSpace(startPositionWC, ray, innerRadius, outerRadius, far, start, startOffset);\n#endif\n#else\n    calculateRayScatteringFromGround(startPositionWC, ray, atmosphereScale, innerRadius, start, startOffset);\n#endif\n\n    // Initialize the scattering loop variables\n    float sampleLength = far / fSamples;\n    float scaledLength = sampleLength * atmosphereScale;\n    vec3 sampleRay = ray * sampleLength;\n    vec3 samplePoint = start + sampleRay * 0.5;\n\n    // Now loop through the sample rays\n    vec3 frontColor = vec3(0.0, 0.0, 0.0);\n\n    for (int i = 0; i<nSamples; i++)\n    {\n        float height = length(samplePoint);\n        float depth = exp((atmosphereScale / rayleighScaleDepth ) * (innerRadius - height));\n        float fLightAngle = dot(lightDirection, samplePoint) / height;\n        float fCameraAngle = dot(ray, samplePoint) / height;\n        float fScatter = (startOffset + depth*(scale(fLightAngle) - scale(fCameraAngle)));\n        vec3 attenuate = exp(-fScatter * (InvWavelength * Kr4PI + Km4PI));\n        frontColor += attenuate * (depth * scaledLength);\n        samplePoint += sampleRay;\n    }\n\n    // Finally, scale the Mie and Rayleigh colors and set up the varying variables for the pixel shader\n    mieColor = frontColor * KmESun;\n    rayleighColor = frontColor * (InvWavelength * KrESun);\n\n    // Cap mie and rayleigh colors to prevent NaNs when vertex interpolation happens\n    mieColor = min(mieColor, vec3(10000000.0));\n    rayleighColor = min(rayleighColor, vec3(10000000.0));\n}\n\nvec4 calculateFinalColor(vec3 positionWC, vec3 toCamera, vec3 lightDirection, vec3 mieColor, vec3 rayleighColor)\n{\n    // Extra normalize added for Android\n    float cosAngle = dot(lightDirection, normalize(toCamera)) / length(toCamera);\n    float rayleighPhase = 0.75 * (1.0 + cosAngle * cosAngle);\n    float miePhase = 1.5 * ((1.0 - g2) / (2.0 + g2)) * (1.0 + cosAngle * cosAngle) / pow(1.0 + g2 - 2.0 * g * cosAngle, 1.5);\n\n    vec3 rgb = rayleighPhase * rayleighColor + miePhase * mieColor;\n\n    const float exposure = 2.0;\n    vec3 rgbExposure = vec3(1.0) - exp(-exposure * rgb);\n\n#ifndef HDR\n    rgb = rgbExposure;\n#endif\n\n#ifdef COLOR_CORRECT\n    // Convert rgb color to hsb\n    vec3 hsb = czm_RGBToHSB(rgb);\n    // Perform hsb shift\n    hsb.x += u_hsbShift.x; // hue\n    hsb.y = clamp(hsb.y + u_hsbShift.y, 0.0, 1.0); // saturation\n    hsb.z = hsb.z > czm_epsilon7 ? hsb.z + u_hsbShift.z : 0.0; // brightness\n    // Convert shifted hsb back to rgb\n    rgb = czm_HSBToRGB(hsb);\n#endif\n\n    float outerRadius = u_radiiAndDynamicAtmosphereColor.x;\n    float innerRadius = u_radiiAndDynamicAtmosphereColor.y;\n    float lightEnum = u_radiiAndDynamicAtmosphereColor.z;\n\n    float cameraHeight = czm_eyeHeight + innerRadius;\n\n    // Alter alpha based on how close the viewer is to the ground (1.0 = on ground, 0.0 = at edge of atmosphere)\n    float atmosphereAlpha = clamp((outerRadius - cameraHeight) / (outerRadius - innerRadius), 0.0, 1.0);\n\n    // Alter alpha based on time of day (0.0 = night , 1.0 = day)\n    float nightAlpha = (lightEnum != 0.0) ? clamp(dot(normalize(positionWC), lightDirection), 0.0, 1.0) : 1.0;\n    atmosphereAlpha *= pow(nightAlpha, 0.5);\n\n    vec4 finalColor = vec4(rgb, mix(clamp(rgbExposure.b, 0.0, 1.0), 1.0, atmosphereAlpha) * smoothstep(0.0, 1.0, czm_morphTime));\n\n    if (mieColor.b > 1.0)\n    {\n        // Fade atmosphere below the ellipsoid. As the camera zooms further away from the ellipsoid draw\n        // a larger atmosphere ring to cover empty space of lower LOD globe tiles.\n        float strength = mieColor.b;\n        float minDistance = outerRadius;\n        float maxDistance = outerRadius * 3.0;\n        float maxStrengthLerp = 1.0 - clamp((maxDistance - cameraHeight) / (maxDistance - minDistance), 0.0, 1.0);\n        float maxStrength = mix(100.0, 10000.0, maxStrengthLerp);\n        strength = min(strength, maxStrength);\n        float alpha = 1.0 - (strength / maxStrength);\n        finalColor.a = alpha;\n    }\n\n    return finalColor;\n}\n"},b71e:function(e,n,t){"use strict";n["a"]="void clipLineSegmentToNearPlane(\n    vec3 p0,\n    vec3 p1,\n    out vec4 positionWC,\n    out bool clipped,\n    out bool culledByNearPlane,\n    out vec4 clippedPositionEC)\n{\n    culledByNearPlane = false;\n    clipped = false;\n\n    vec3 p0ToP1 = p1 - p0;\n    float magnitude = length(p0ToP1);\n    vec3 direction = normalize(p0ToP1);\n\n    // Distance that p0 is behind the near plane. Negative means p0 is\n    // in front of the near plane.\n    float endPoint0Distance =  czm_currentFrustum.x + p0.z;\n\n    // Camera looks down -Z.\n    // When moving a point along +Z: LESS VISIBLE\n    //   * Points in front of the camera move closer to the camera.\n    //   * Points behind the camrea move farther away from the camera.\n    // When moving a point along -Z: MORE VISIBLE\n    //   * Points in front of the camera move farther away from the camera.\n    //   * Points behind the camera move closer to the camera.\n\n    // Positive denominator: -Z, becoming more visible\n    // Negative denominator: +Z, becoming less visible\n    // Nearly zero: parallel to near plane\n    float denominator = -direction.z;\n\n    if (endPoint0Distance > 0.0 && abs(denominator) < czm_epsilon7)\n    {\n        // p0 is behind the near plane and the line to p1 is nearly parallel to\n        // the near plane, so cull the segment completely.\n        culledByNearPlane = true;\n    }\n    else if (endPoint0Distance > 0.0)\n    {\n        // p0 is behind the near plane, and the line to p1 is moving distinctly\n        // toward or away from it.\n\n        // t = (-plane distance - dot(plane normal, ray origin)) / dot(plane normal, ray direction)\n        float t = endPoint0Distance / denominator;\n        if (t < 0.0 || t > magnitude)\n        {\n            // Near plane intersection is not between the two points.\n            // We already confirmed p0 is behind the naer plane, so now\n            // we know the entire segment is behind it.\n            culledByNearPlane = true;\n        }\n        else\n        {\n            // Segment crosses the near plane, update p0 to lie exactly on it.\n            p0 = p0 + t * direction;\n\n            // Numerical noise might put us a bit on the wrong side of the near plane.\n            // Don't let that happen.\n            p0.z = min(p0.z, -czm_currentFrustum.x);\n\n            clipped = true;\n        }\n    }\n\n    clippedPositionEC = vec4(p0, 1.0);\n    positionWC = czm_eyeToWindowCoordinates(clippedPositionEC);\n}\n\nvec4 getPolylineWindowCoordinatesEC(vec4 positionEC, vec4 prevEC, vec4 nextEC, float expandDirection, float width, bool usePrevious, out float angle)\n{\n    // expandDirection +1 is to the _left_ when looking from positionEC toward nextEC.\n\n#ifdef POLYLINE_DASH\n    // Compute the window coordinates of the points.\n    vec4 positionWindow = czm_eyeToWindowCoordinates(positionEC);\n    vec4 previousWindow = czm_eyeToWindowCoordinates(prevEC);\n    vec4 nextWindow = czm_eyeToWindowCoordinates(nextEC);\n\n    // Determine the relative screen space direction of the line.\n    vec2 lineDir;\n    if (usePrevious) {\n        lineDir = normalize(positionWindow.xy - previousWindow.xy);\n    }\n    else {\n        lineDir = normalize(nextWindow.xy - positionWindow.xy);\n    }\n    angle = atan(lineDir.x, lineDir.y) - 1.570796327; // precomputed atan(1,0)\n\n    // Quantize the angle so it doesn't change rapidly between segments.\n    angle = floor(angle / czm_piOverFour + 0.5) * czm_piOverFour;\n#endif\n\n    vec4 clippedPrevWC, clippedPrevEC;\n    bool prevSegmentClipped, prevSegmentCulled;\n    clipLineSegmentToNearPlane(prevEC.xyz, positionEC.xyz, clippedPrevWC, prevSegmentClipped, prevSegmentCulled, clippedPrevEC);\n\n    vec4 clippedNextWC, clippedNextEC;\n    bool nextSegmentClipped, nextSegmentCulled;\n    clipLineSegmentToNearPlane(nextEC.xyz, positionEC.xyz, clippedNextWC, nextSegmentClipped, nextSegmentCulled, clippedNextEC);\n\n    bool segmentClipped, segmentCulled;\n    vec4 clippedPositionWC, clippedPositionEC;\n    clipLineSegmentToNearPlane(positionEC.xyz, usePrevious ? prevEC.xyz : nextEC.xyz, clippedPositionWC, segmentClipped, segmentCulled, clippedPositionEC);\n\n    if (segmentCulled)\n    {\n        return vec4(0.0, 0.0, 0.0, 1.0);\n    }\n\n    vec2 directionToPrevWC = normalize(clippedPrevWC.xy - clippedPositionWC.xy);\n    vec2 directionToNextWC = normalize(clippedNextWC.xy - clippedPositionWC.xy);\n\n    // If a segment was culled, we can't use the corresponding direction\n    // computed above. We should never see both of these be true without\n    // `segmentCulled` above also being true.\n    if (prevSegmentCulled)\n    {\n        directionToPrevWC = -directionToNextWC;\n    }\n    else if (nextSegmentCulled)\n    {\n        directionToNextWC = -directionToPrevWC;\n    }\n\n    vec2 thisSegmentForwardWC, otherSegmentForwardWC;\n    if (usePrevious)\n    {\n        thisSegmentForwardWC = -directionToPrevWC;\n        otherSegmentForwardWC = directionToNextWC;\n    }\n    else\n    {\n        thisSegmentForwardWC = directionToNextWC;\n        otherSegmentForwardWC =  -directionToPrevWC;\n    }\n\n    vec2 thisSegmentLeftWC = vec2(-thisSegmentForwardWC.y, thisSegmentForwardWC.x);\n\n    vec2 leftWC = thisSegmentLeftWC;\n    float expandWidth = width * 0.5;\n\n    // When lines are split at the anti-meridian, the position may be at the\n    // same location as the next or previous position, and we need to handle\n    // that to avoid producing NaNs.\n    if (!czm_equalsEpsilon(prevEC.xyz - positionEC.xyz, vec3(0.0), czm_epsilon1) && !czm_equalsEpsilon(nextEC.xyz - positionEC.xyz, vec3(0.0), czm_epsilon1))\n    {\n        vec2 otherSegmentLeftWC = vec2(-otherSegmentForwardWC.y, otherSegmentForwardWC.x);\n\n        vec2 leftSumWC = thisSegmentLeftWC + otherSegmentLeftWC;\n        float leftSumLength = length(leftSumWC);\n        leftWC = leftSumLength < czm_epsilon6 ? thisSegmentLeftWC : (leftSumWC / leftSumLength);\n\n        // The sine of the angle between the two vectors is given by the formula\n        //         |a x b| = |a||b|sin(theta)\n        // which is\n        //     float sinAngle = length(cross(vec3(leftWC, 0.0), vec3(-thisSegmentForwardWC, 0.0)));\n        // Because the z components of both vectors are zero, the x and y coordinate will be zero.\n        // Therefore, the sine of the angle is just the z component of the cross product.\n        vec2 u = -thisSegmentForwardWC;\n        vec2 v = leftWC;\n        float sinAngle = abs(u.x * v.y - u.y * v.x);\n        expandWidth = clamp(expandWidth / sinAngle, 0.0, width * 2.0);\n    }\n\n    vec2 offset = leftWC * expandDirection * expandWidth * czm_pixelRatio;\n    return vec4(clippedPositionWC.xy + offset, -clippedPositionWC.z, 1.0) * (czm_projection * clippedPositionEC).w;\n}\n\nvec4 getPolylineWindowCoordinates(vec4 position, vec4 previous, vec4 next, float expandDirection, float width, bool usePrevious, out float angle)\n{\n    vec4 positionEC = czm_modelViewRelativeToEye * position;\n    vec4 prevEC = czm_modelViewRelativeToEye * previous;\n    vec4 nextEC = czm_modelViewRelativeToEye * next;\n    return getPolylineWindowCoordinatesEC(positionEC, prevEC, nextEC, expandDirection, width, usePrevious, angle);\n}\n"},bc38:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\nfloat rand(vec2 co)\n{\n    return fract(sin(dot(co.xy ,vec2(12.9898, 78.233))) * 43758.5453);\n}\n\nvoid main(void)\n{\n    float noiseValue = rand(v_textureCoordinates + sin(czm_frameNumber)) * 0.1;\n    vec3 rgb = texture2D(colorTexture, v_textureCoordinates).rgb;\n    vec3 green = vec3(0.0, 1.0, 0.0);\n    gl_FragColor = vec4((noiseValue + rgb) * green, 1.0);\n}\n"},bdad:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform float brightness;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 rgb = texture2D(colorTexture, v_textureCoordinates).rgb;\n    vec3 target = vec3(0.0);\n    gl_FragColor = vec4(mix(target, rgb, brightness), 1.0);\n}\n"},bfb2:function(e,n,t){"use strict";n["a"]="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 position2DHigh;\nattribute vec3 position2DLow;\nattribute vec3 prevPosition3DHigh;\nattribute vec3 prevPosition3DLow;\nattribute vec3 prevPosition2DHigh;\nattribute vec3 prevPosition2DLow;\nattribute vec3 nextPosition3DHigh;\nattribute vec3 nextPosition3DLow;\nattribute vec3 nextPosition2DHigh;\nattribute vec3 nextPosition2DLow;\nattribute vec4 texCoordExpandAndBatchIndex;\n\nvarying vec2  v_st;\nvarying float v_width;\nvarying vec4 v_pickColor;\nvarying float v_polylineAngle;\n\nvoid main()\n{\n    float texCoord = texCoordExpandAndBatchIndex.x;\n    float expandDir = texCoordExpandAndBatchIndex.y;\n    bool usePrev = texCoordExpandAndBatchIndex.z < 0.0;\n    float batchTableIndex = texCoordExpandAndBatchIndex.w;\n\n    vec2 widthAndShow = batchTable_getWidthAndShow(batchTableIndex);\n    float width = widthAndShow.x + 0.5;\n    float show = widthAndShow.y;\n\n    if (width < 1.0)\n    {\n        show = 0.0;\n    }\n\n    vec4 pickColor = batchTable_getPickColor(batchTableIndex);\n\n    vec4 p, prev, next;\n    if (czm_morphTime == 1.0)\n    {\n        p = czm_translateRelativeToEye(position3DHigh.xyz, position3DLow.xyz);\n        prev = czm_translateRelativeToEye(prevPosition3DHigh.xyz, prevPosition3DLow.xyz);\n        next = czm_translateRelativeToEye(nextPosition3DHigh.xyz, nextPosition3DLow.xyz);\n    }\n    else if (czm_morphTime == 0.0)\n    {\n        p = czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy);\n        prev = czm_translateRelativeToEye(prevPosition2DHigh.zxy, prevPosition2DLow.zxy);\n        next = czm_translateRelativeToEye(nextPosition2DHigh.zxy, nextPosition2DLow.zxy);\n    }\n    else\n    {\n        p = czm_columbusViewMorph(\n                czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy),\n                czm_translateRelativeToEye(position3DHigh.xyz, position3DLow.xyz),\n                czm_morphTime);\n        prev = czm_columbusViewMorph(\n                czm_translateRelativeToEye(prevPosition2DHigh.zxy, prevPosition2DLow.zxy),\n                czm_translateRelativeToEye(prevPosition3DHigh.xyz, prevPosition3DLow.xyz),\n                czm_morphTime);\n        next = czm_columbusViewMorph(\n                czm_translateRelativeToEye(nextPosition2DHigh.zxy, nextPosition2DLow.zxy),\n                czm_translateRelativeToEye(nextPosition3DHigh.xyz, nextPosition3DLow.xyz),\n                czm_morphTime);\n    }\n\n    #ifdef DISTANCE_DISPLAY_CONDITION\n        vec3 centerHigh = batchTable_getCenterHigh(batchTableIndex);\n        vec4 centerLowAndRadius = batchTable_getCenterLowAndRadius(batchTableIndex);\n        vec3 centerLow = centerLowAndRadius.xyz;\n        float radius = centerLowAndRadius.w;\n        vec2 distanceDisplayCondition = batchTable_getDistanceDisplayCondition(batchTableIndex);\n\n        float lengthSq;\n        if (czm_sceneMode == czm_sceneMode2D)\n        {\n            lengthSq = czm_eyeHeight2D.y;\n        }\n        else\n        {\n            vec4 center = czm_translateRelativeToEye(centerHigh.xyz, centerLow.xyz);\n            lengthSq = max(0.0, dot(center.xyz, center.xyz) - radius * radius);\n        }\n\n        float nearSq = distanceDisplayCondition.x * distanceDisplayCondition.x;\n        float farSq = distanceDisplayCondition.y * distanceDisplayCondition.y;\n        if (lengthSq < nearSq || lengthSq > farSq)\n        {\n            show = 0.0;\n        }\n    #endif\n\n    float polylineAngle;\n    vec4 positionWC = getPolylineWindowCoordinates(p, prev, next, expandDir, width, usePrev, polylineAngle);\n    gl_Position = czm_viewportOrthographic * positionWC * show;\n\n    v_st.s = texCoord;\n    v_st.t = czm_writeNonPerspective(clamp(expandDir, 0.0, 1.0), gl_Position.w);\n\n    v_width = width;\n    v_pickColor = pickColor;\n    v_polylineAngle = polylineAngle;\n}\n"},bfce:function(e,n,t){"use strict";n["a"]="#extension GL_EXT_frag_depth : enable\n\nuniform sampler2D u_pointCloud_colorGBuffer;\nuniform sampler2D u_pointCloud_depthGBuffer;\nuniform vec2 u_distanceAndEdlStrength;\nvarying vec2 v_textureCoordinates;\n\nvec2 neighborContribution(float log2Depth, vec2 offset)\n{\n    float dist = u_distanceAndEdlStrength.x;\n    vec2 texCoordOrig = v_textureCoordinates + offset * dist;\n    vec2 texCoord0 = v_textureCoordinates + offset * floor(dist);\n    vec2 texCoord1 = v_textureCoordinates + offset * ceil(dist);\n\n    float depthOrLogDepth0 = czm_unpackDepth(texture2D(u_pointCloud_depthGBuffer, texCoord0));\n    float depthOrLogDepth1 = czm_unpackDepth(texture2D(u_pointCloud_depthGBuffer, texCoord1));\n\n    // ignore depth values that are the clear depth\n    if (depthOrLogDepth0 == 0.0 || depthOrLogDepth1 == 0.0) {\n        return vec2(0.0);\n    }\n\n    // interpolate the two adjacent depth values\n    float depthMix = mix(depthOrLogDepth0, depthOrLogDepth1, fract(dist));\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(texCoordOrig, depthMix);\n    return vec2(max(0.0, log2Depth - log2(-eyeCoordinate.z / eyeCoordinate.w)), 1.0);\n}\n\nvoid main()\n{\n    float depthOrLogDepth = czm_unpackDepth(texture2D(u_pointCloud_depthGBuffer, v_textureCoordinates));\n\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, depthOrLogDepth);\n    eyeCoordinate /= eyeCoordinate.w;\n\n    float log2Depth = log2(-eyeCoordinate.z);\n\n    if (depthOrLogDepth == 0.0) // 0.0 is the clear value for the gbuffer\n    {\n        discard;\n    }\n\n    vec4 color = texture2D(u_pointCloud_colorGBuffer, v_textureCoordinates);\n\n    // sample from neighbors left, right, down, up\n    vec2 texelSize = 1.0 / czm_viewport.zw;\n\n    vec2 responseAndCount = vec2(0.0);\n\n    responseAndCount += neighborContribution(log2Depth, vec2(-texelSize.x, 0.0));\n    responseAndCount += neighborContribution(log2Depth, vec2(+texelSize.x, 0.0));\n    responseAndCount += neighborContribution(log2Depth, vec2(0.0, -texelSize.y));\n    responseAndCount += neighborContribution(log2Depth, vec2(0.0, +texelSize.y));\n\n    float response = responseAndCount.x / responseAndCount.y;\n    float strength = u_distanceAndEdlStrength.y;\n    float shade = exp(-response * 300.0 * strength);\n    color.rgb *= shade;\n    gl_FragColor = vec4(color);\n\n    // Input and output depth are the same.\n    gl_FragDepthEXT = depthOrLogDepth;\n}\n"},c470:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\n// See equation 3:\n//    http://www.cs.utah.edu/~reinhard/cdrom/tonemap.pdf\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n#ifdef AUTO_EXPOSURE\n    float exposure = texture2D(autoExposure, vec2(0.5)).r;\n    color /= exposure;\n#endif\n    color = color / (1.0 + color);\n    color = czm_inverseGamma(color);\n    gl_FragColor = vec4(color, fragmentColor.a);\n}\n"},c730:function(e,n,t){"use strict";n["a"]="attribute vec4 position;\nattribute float webMercatorT;\n\nuniform vec2 u_textureDimensions;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    v_textureCoordinates = vec2(position.x, webMercatorT);\n    gl_Position = czm_viewportOrthographic * (position * vec4(u_textureDimensions, 1.0, 1.0));\n}\n"},e187:function(e,n,t){"use strict";n["a"]="#ifdef VECTOR_TILE\nuniform vec4 u_highlightColor;\n#endif\n\nvarying vec2 v_st;\n\nvoid main()\n{\n    czm_materialInput materialInput;\n\n    vec2 st = v_st;\n    st.t = czm_readNonPerspective(st.t, gl_FragCoord.w);\n\n    materialInput.s = st.s;\n    materialInput.st = st;\n    materialInput.str = vec3(st, 0.0);\n\n    czm_material material = czm_getMaterial(materialInput);\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#ifdef VECTOR_TILE\n    gl_FragColor *= u_highlightColor;\n#endif\n\n    czm_writeLogDepth();\n}\n"},e3b4:function(e,n,t){"use strict";n["a"]='attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\n\n// In 2D and in 3D, texture coordinate normalization component signs encodes:\n// * X sign - sidedness relative to right plane\n// * Y sign - is negative OR magnitude is greater than 1.0 if vertex is on bottom of volume\n#ifndef COLUMBUS_VIEW_2D\nattribute vec4 startHiAndForwardOffsetX;\nattribute vec4 startLoAndForwardOffsetY;\nattribute vec4 startNormalAndForwardOffsetZ;\nattribute vec4 endNormalAndTextureCoordinateNormalizationX;\nattribute vec4 rightNormalAndTextureCoordinateNormalizationY;\n#else\nattribute vec4 startHiLo2D;\nattribute vec4 offsetAndRight2D;\nattribute vec4 startEndNormals2D;\nattribute vec2 texcoordNormalization2D;\n#endif\n\nattribute float batchId;\n\nvarying vec4 v_startPlaneNormalEcAndHalfWidth;\nvarying vec4 v_endPlaneNormalEcAndBatchId;\nvarying vec4 v_rightPlaneEC;\nvarying vec4 v_endEcAndStartEcX;\nvarying vec4 v_texcoordNormalizationAndStartEcYZ;\n\n// For materials\n#ifdef WIDTH_VARYING\nvarying float v_width;\n#endif\n#ifdef ANGLE_VARYING\nvarying float v_polylineAngle;\n#endif\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif\n\nvoid main()\n{\n#ifdef COLUMBUS_VIEW_2D\n    vec3 ecStart = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, startHiLo2D.xy), vec3(0.0, startHiLo2D.zw))).xyz;\n\n    vec3 forwardDirectionEC = czm_normal * vec3(0.0, offsetAndRight2D.xy);\n    vec3 ecEnd = forwardDirectionEC + ecStart;\n    forwardDirectionEC = normalize(forwardDirectionEC);\n\n    // Right plane\n    v_rightPlaneEC.xyz = czm_normal * vec3(0.0, offsetAndRight2D.zw);\n    v_rightPlaneEC.w = -dot(v_rightPlaneEC.xyz, ecStart);\n\n    // start plane\n    vec4 startPlaneEC;\n    startPlaneEC.xyz =  czm_normal * vec3(0.0, startEndNormals2D.xy);\n    startPlaneEC.w = -dot(startPlaneEC.xyz, ecStart);\n\n    // end plane\n    vec4 endPlaneEC;\n    endPlaneEC.xyz =  czm_normal * vec3(0.0, startEndNormals2D.zw);\n    endPlaneEC.w = -dot(endPlaneEC.xyz, ecEnd);\n\n    v_texcoordNormalizationAndStartEcYZ.x = abs(texcoordNormalization2D.x);\n    v_texcoordNormalizationAndStartEcYZ.y = texcoordNormalization2D.y;\n\n#else // COLUMBUS_VIEW_2D\n    vec3 ecStart = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(startHiAndForwardOffsetX.xyz, startLoAndForwardOffsetY.xyz)).xyz;\n    vec3 offset = czm_normal * vec3(startHiAndForwardOffsetX.w, startLoAndForwardOffsetY.w, startNormalAndForwardOffsetZ.w);\n    vec3 ecEnd = ecStart + offset;\n\n    vec3 forwardDirectionEC = normalize(offset);\n\n    // start plane\n    vec4 startPlaneEC;\n    startPlaneEC.xyz = czm_normal * startNormalAndForwardOffsetZ.xyz;\n    startPlaneEC.w = -dot(startPlaneEC.xyz, ecStart);\n\n    // end plane\n    vec4 endPlaneEC;\n    endPlaneEC.xyz = czm_normal * endNormalAndTextureCoordinateNormalizationX.xyz;\n    endPlaneEC.w = -dot(endPlaneEC.xyz, ecEnd);\n\n    // Right plane\n    v_rightPlaneEC.xyz = czm_normal * rightNormalAndTextureCoordinateNormalizationY.xyz;\n    v_rightPlaneEC.w = -dot(v_rightPlaneEC.xyz, ecStart);\n\n    v_texcoordNormalizationAndStartEcYZ.x = abs(endNormalAndTextureCoordinateNormalizationX.w);\n    v_texcoordNormalizationAndStartEcYZ.y = rightNormalAndTextureCoordinateNormalizationY.w;\n\n#endif // COLUMBUS_VIEW_2D\n\n    v_endEcAndStartEcX.xyz = ecEnd;\n    v_endEcAndStartEcX.w = ecStart.x;\n    v_texcoordNormalizationAndStartEcYZ.zw = ecStart.yz;\n\n#ifdef PER_INSTANCE_COLOR\n    v_color = czm_batchTable_color(batchId);\n#endif // PER_INSTANCE_COLOR\n\n    // Compute a normal along which to "push" the position out, extending the miter depending on view distance.\n    // Position has already been "pushed" by unit length along miter normal, and miter normals are encoded in the planes.\n    // Decode the normal to use at this specific vertex, push the position back, and then push to where it needs to be.\n    vec4 positionRelativeToEye = czm_computePosition();\n\n    // Check distance to the end plane and start plane, pick the plane that is closer\n    vec4 positionEC = czm_modelViewRelativeToEye * positionRelativeToEye; // w = 1.0, see czm_computePosition\n    float absStartPlaneDistance = abs(czm_planeDistance(startPlaneEC, positionEC.xyz));\n    float absEndPlaneDistance = abs(czm_planeDistance(endPlaneEC, positionEC.xyz));\n    vec3 planeDirection = czm_branchFreeTernary(absStartPlaneDistance < absEndPlaneDistance, startPlaneEC.xyz, endPlaneEC.xyz);\n    vec3 upOrDown = normalize(cross(v_rightPlaneEC.xyz, planeDirection)); // Points "up" for start plane, "down" at end plane.\n    vec3 normalEC = normalize(cross(planeDirection, upOrDown));           // In practice, the opposite seems to work too.\n\n    // Extrude bottom vertices downward for far view distances, like for GroundPrimitives\n    upOrDown = cross(forwardDirectionEC, normalEC);\n    upOrDown = float(czm_sceneMode == czm_sceneMode3D) * upOrDown;\n    upOrDown = float(v_texcoordNormalizationAndStartEcYZ.y > 1.0 || v_texcoordNormalizationAndStartEcYZ.y < 0.0) * upOrDown;\n    upOrDown = min(GLOBE_MINIMUM_ALTITUDE, czm_geometricToleranceOverMeter * length(positionRelativeToEye.xyz)) * upOrDown;\n    positionEC.xyz += upOrDown;\n\n    v_texcoordNormalizationAndStartEcYZ.y = czm_branchFreeTernary(v_texcoordNormalizationAndStartEcYZ.y > 1.0, 0.0, abs(v_texcoordNormalizationAndStartEcYZ.y));\n\n    // Determine distance along normalEC to push for a volume of appropriate width.\n    // Make volumes about double pixel width for a conservative fit - in practice the\n    // extra cost here is minimal compared to the loose volume heights.\n    //\n    // N = normalEC (guaranteed "right-facing")\n    // R = rightEC\n    // p = angle between N and R\n    // w = distance to push along R if R == N\n    // d = distance to push along N\n    //\n    //   N   R\n    //  {  p| }      * cos(p) = dot(N, R) = w / d\n    //  d  |  |w    * d = w / dot(N, R)\n    //    { | }\n    //       o---------- polyline segment ----\x3e\n    //\n    float width = czm_batchTable_width(batchId);\n#ifdef WIDTH_VARYING\n    v_width = width;\n#endif\n\n    v_startPlaneNormalEcAndHalfWidth.xyz = startPlaneEC.xyz;\n    v_startPlaneNormalEcAndHalfWidth.w = width * 0.5;\n\n    v_endPlaneNormalEcAndBatchId.xyz = endPlaneEC.xyz;\n    v_endPlaneNormalEcAndBatchId.w = batchId;\n\n    width = width * max(0.0, czm_metersPerPixel(positionEC)); // width = distance to push along R\n    width = width / dot(normalEC, v_rightPlaneEC.xyz); // width = distance to push along N\n\n    // Determine if this vertex is on the "left" or "right"\n#ifdef COLUMBUS_VIEW_2D\n        normalEC *= sign(texcoordNormalization2D.x);\n#else\n        normalEC *= sign(endNormalAndTextureCoordinateNormalizationX.w);\n#endif\n\n    positionEC.xyz += width * normalEC;\n    gl_Position = czm_depthClamp(czm_projection * positionEC);\n\n#ifdef ANGLE_VARYING\n    // Approximate relative screen space direction of the line.\n    vec2 approxLineDirection = normalize(vec2(forwardDirectionEC.x, -forwardDirectionEC.y));\n    approxLineDirection.y = czm_branchFreeTernary(approxLineDirection.x == 0.0 && approxLineDirection.y == 0.0, -1.0, approxLineDirection.y);\n    v_polylineAngle = czm_fastApproximateAtan(approxLineDirection.x, approxLineDirection.y);\n#endif\n}\n'},ef10:function(e,n,t){"use strict";n["a"]="varying vec3 v_outerPositionWC;\n\n#ifndef PER_FRAGMENT_ATMOSPHERE\nvarying vec3 v_mieColor;\nvarying vec3 v_rayleighColor;\n#endif\n\nvoid main (void)\n{\n    vec3 toCamera = czm_viewerPositionWC - v_outerPositionWC;\n    vec3 lightDirection = getLightDirection(czm_viewerPositionWC);\n    vec3 mieColor;\n    vec3 rayleighColor;\n\n#ifdef PER_FRAGMENT_ATMOSPHERE\n    calculateMieColorAndRayleighColor(v_outerPositionWC, mieColor, rayleighColor);\n#else\n    mieColor = v_mieColor;\n    rayleighColor = v_rayleighColor;\n#endif\n\n    gl_FragColor = calculateFinalColor(czm_viewerPositionWC, toCamera, lightDirection, mieColor, rayleighColor);\n}\n"},f1e5:function(e,n,t){"use strict";n["a"]="uniform sampler2D colorTexture;\nuniform sampler2D dirtTexture;\nuniform sampler2D starTexture;\nuniform vec2 dirtTextureDimensions;\nuniform float distortion;\nuniform float ghostDispersal;\nuniform float haloWidth;\nuniform float dirtAmount;\nuniform float earthRadius;\nuniform float intensity;\n\nvarying vec2 v_textureCoordinates;\n\n// whether it is in space or not\n// 6500000.0 is empirical value\n#define DISTANCE_TO_SPACE 6500000.0\n\n// return ndc from world coordinate biased earthRadius\nvec4 getNDCFromWC(vec3 WC, float earthRadius)\n{\n    vec4 positionEC = czm_view * vec4(WC, 1.0);\n    positionEC = vec4(positionEC.x + earthRadius, positionEC.y, positionEC.z, 1.0);\n    vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n    return czm_viewportOrthographic * vec4(positionWC.xy, -positionWC.z, 1.0);\n}\n\n// Check if current pixel is included Earth\n// if then mask it gradually\nfloat isInEarth(vec2 texcoord, vec2 sceneSize)\n{\n    vec2 NDC = texcoord * 2.0 - 1.0;\n    vec4 earthPosSC = getNDCFromWC(vec3(0.0), 0.0);\n    vec4 earthPosSCEdge = getNDCFromWC(vec3(0.0), earthRadius * 1.5);\n    NDC.xy -= earthPosSC.xy;\n\n    float X = abs(NDC.x) * sceneSize.x;\n    float Y = abs(NDC.y) * sceneSize.y;\n\n    return clamp(0.0, 1.0, max(sqrt(X * X + Y * Y) / max(abs(earthPosSCEdge.x * sceneSize.x), 1.0) - 0.8 , 0.0));\n}\n\n// For Chromatic effect\nvec4 textureDistorted(sampler2D tex, vec2 texcoord, vec2 direction, vec3 distortion, bool isSpace)\n{\n    vec2 sceneSize = czm_viewport.zw;\n    vec3 color;\n    if(isSpace)\n    {\n        color.r = isInEarth(texcoord + direction * distortion.r, sceneSize) * texture2D(tex, texcoord + direction * distortion.r).r;\n        color.g = isInEarth(texcoord + direction * distortion.g, sceneSize) * texture2D(tex, texcoord + direction * distortion.g).g;\n        color.b = isInEarth(texcoord + direction * distortion.b, sceneSize) * texture2D(tex, texcoord + direction * distortion.b).b;\n    }\n    else\n    {\n        color.r = texture2D(tex, texcoord + direction * distortion.r).r;\n        color.g = texture2D(tex, texcoord + direction * distortion.g).g;\n        color.b = texture2D(tex, texcoord + direction * distortion.b).b;\n    }\n    return vec4(clamp(color, 0.0, 1.0), 0.0);\n}\n\nvoid main(void)\n{\n    vec4 originalColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 rgb = originalColor.rgb;\n    bool isSpace = length(czm_viewerPositionWC.xyz) > DISTANCE_TO_SPACE;\n\n    // Sun position\n    vec4 sunPos = czm_morphTime == 1.0 ? vec4(czm_sunPositionWC, 1.0) : vec4(czm_sunPositionColumbusView.zxy, 1.0);\n    vec4 sunPositionEC = czm_view * sunPos;\n    vec4 sunPositionWC = czm_eyeToWindowCoordinates(sunPositionEC);\n    sunPos = czm_viewportOrthographic * vec4(sunPositionWC.xy, -sunPositionWC.z, 1.0);\n\n    // If sun is not in the screen space, use original color.\n    if(!isSpace || !((sunPos.x >= -1.1 && sunPos.x <= 1.1) && (sunPos.y >= -1.1 && sunPos.y <= 1.1)))\n    {\n        // Lens flare is disabled when not in space until #5932 is fixed.\n        //    https://github.com/CesiumGS/cesium/issues/5932\n        gl_FragColor = originalColor;\n        return;\n    }\n\n    vec2 texcoord = vec2(1.0) - v_textureCoordinates;\n    vec2 pixelSize = czm_pixelRatio / czm_viewport.zw;\n    vec2 invPixelSize = 1.0 / pixelSize;\n    vec3 distortionVec = pixelSize.x * vec3(-distortion, 0.0, distortion);\n\n    // ghost vector to image centre:\n    vec2 ghostVec = (vec2(0.5) - texcoord) * ghostDispersal;\n    vec3 direction = normalize(vec3(ghostVec, 0.0));\n\n    // sample ghosts:\n    vec4 result = vec4(0.0);\n    vec4 ghost = vec4(0.0);\n    for (int i = 0; i < 4; ++i)\n    {\n        vec2 offset = fract(texcoord + ghostVec * float(i));\n        // Only bright spots from the centre of the source image\n        ghost += textureDistorted(colorTexture, offset, direction.xy, distortionVec, isSpace);\n    }\n    result += ghost;\n\n    // sample halo\n    vec2 haloVec = normalize(ghostVec) * haloWidth;\n    float weightForHalo = length(vec2(0.5) - fract(texcoord + haloVec)) / length(vec2(0.5));\n    weightForHalo = pow(1.0 - weightForHalo, 5.0);\n\n    result += textureDistorted(colorTexture, texcoord + haloVec, direction.xy, distortionVec, isSpace) * weightForHalo * 1.5;\n\n    // dirt on lens\n    vec2 dirtTexCoords = (v_textureCoordinates * invPixelSize) / dirtTextureDimensions;\n    if (dirtTexCoords.x > 1.0)\n    {\n        dirtTexCoords.x = mod(floor(dirtTexCoords.x), 2.0) == 1.0 ? 1.0 - fract(dirtTexCoords.x) :  fract(dirtTexCoords.x);\n    }\n    if (dirtTexCoords.y > 1.0)\n    {\n        dirtTexCoords.y = mod(floor(dirtTexCoords.y), 2.0) == 1.0 ? 1.0 - fract(dirtTexCoords.y) :  fract(dirtTexCoords.y);\n    }\n    result += dirtAmount * texture2D(dirtTexture, dirtTexCoords);\n\n    // Rotating starburst texture's coordinate\n    // dot(czm_view[0].xyz, vec3(0.0, 0.0, 1.0)) + dot(czm_view[1].xyz, vec3(0.0, 1.0, 0.0))\n    float camrot = czm_view[0].z + czm_view[1].y;\n    float cosValue = cos(camrot);\n    float sinValue = sin(camrot);\n    mat3 rotation = mat3(\n        cosValue, -sinValue, 0.0,\n        sinValue, cosValue, 0.0,\n        0.0, 0.0, 1.0\n    );\n\n    vec3 st1 = vec3(v_textureCoordinates * 2.0 - vec2(1.0), 1.0);\n    vec3 st2 = vec3((rotation * st1).xy, 1.0);\n    vec3 st3 = st2 * 0.5 + vec3(0.5);\n    vec2 lensStarTexcoord = st3.xy;\n    float weightForLensFlare = length(vec3(sunPos.xy, 0.0));\n    float oneMinusWeightForLensFlare = max(1.0 - weightForLensFlare, 0.0);\n\n    if (!isSpace)\n    {\n        result *= oneMinusWeightForLensFlare * intensity * 0.2;\n    }\n    else\n    {\n        result *= oneMinusWeightForLensFlare * intensity;\n        result *= texture2D(starTexture, lensStarTexcoord) * pow(weightForLensFlare, 1.0) * max((1.0 - length(vec3(st1.xy, 0.0))), 0.0) * 2.0;\n    }\n\n    result += texture2D(colorTexture, v_textureCoordinates);\n\n    gl_FragColor = result;\n}\n"},fb17:function(e,n,t){"use strict";n["a"]='attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\n\nattribute vec4 startHiAndForwardOffsetX;\nattribute vec4 startLoAndForwardOffsetY;\nattribute vec4 startNormalAndForwardOffsetZ;\nattribute vec4 endNormalAndTextureCoordinateNormalizationX;\nattribute vec4 rightNormalAndTextureCoordinateNormalizationY;\nattribute vec4 startHiLo2D;\nattribute vec4 offsetAndRight2D;\nattribute vec4 startEndNormals2D;\nattribute vec2 texcoordNormalization2D;\n\nattribute float batchId;\n\nvarying vec3 v_forwardDirectionEC;\nvarying vec3 v_texcoordNormalizationAndHalfWidth;\nvarying float v_batchId;\n\n// For materials\n#ifdef WIDTH_VARYING\nvarying float v_width;\n#endif\n#ifdef ANGLE_VARYING\nvarying float v_polylineAngle;\n#endif\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#else\nvarying vec2 v_alignedPlaneDistances;\nvarying float v_texcoordT;\n#endif\n\n// Morphing planes using SLERP or NLERP doesn\'t seem to work, so instead draw the material directly on the shadow volume.\n// Morph views are from very far away and aren\'t meant to be used precisely, so this should be sufficient.\nvoid main()\n{\n    v_batchId = batchId;\n\n    // Start position\n    vec4 posRelativeToEye2D = czm_translateRelativeToEye(vec3(0.0, startHiLo2D.xy), vec3(0.0, startHiLo2D.zw));\n    vec4 posRelativeToEye3D = czm_translateRelativeToEye(startHiAndForwardOffsetX.xyz, startLoAndForwardOffsetY.xyz);\n    vec4 posRelativeToEye = czm_columbusViewMorph(posRelativeToEye2D, posRelativeToEye3D, czm_morphTime);\n    vec3 posEc2D = (czm_modelViewRelativeToEye * posRelativeToEye2D).xyz;\n    vec3 posEc3D = (czm_modelViewRelativeToEye * posRelativeToEye3D).xyz;\n    vec3 startEC = (czm_modelViewRelativeToEye * posRelativeToEye).xyz;\n\n    // Start plane\n    vec4 startPlane2D;\n    vec4 startPlane3D;\n    startPlane2D.xyz = czm_normal * vec3(0.0, startEndNormals2D.xy);\n    startPlane3D.xyz = czm_normal * startNormalAndForwardOffsetZ.xyz;\n    startPlane2D.w = -dot(startPlane2D.xyz, posEc2D);\n    startPlane3D.w = -dot(startPlane3D.xyz, posEc3D);\n\n    // Right plane\n    vec4 rightPlane2D;\n    vec4 rightPlane3D;\n    rightPlane2D.xyz = czm_normal * vec3(0.0, offsetAndRight2D.zw);\n    rightPlane3D.xyz = czm_normal * rightNormalAndTextureCoordinateNormalizationY.xyz;\n    rightPlane2D.w = -dot(rightPlane2D.xyz, posEc2D);\n    rightPlane3D.w = -dot(rightPlane3D.xyz, posEc3D);\n\n    // End position\n    posRelativeToEye2D = posRelativeToEye2D + vec4(0.0, offsetAndRight2D.xy, 0.0);\n    posRelativeToEye3D = posRelativeToEye3D + vec4(startHiAndForwardOffsetX.w, startLoAndForwardOffsetY.w, startNormalAndForwardOffsetZ.w, 0.0);\n    posRelativeToEye = czm_columbusViewMorph(posRelativeToEye2D, posRelativeToEye3D, czm_morphTime);\n    posEc2D = (czm_modelViewRelativeToEye * posRelativeToEye2D).xyz;\n    posEc3D = (czm_modelViewRelativeToEye * posRelativeToEye3D).xyz;\n    vec3 endEC = (czm_modelViewRelativeToEye * posRelativeToEye).xyz;\n    vec3 forwardEc3D = czm_normal * normalize(vec3(startHiAndForwardOffsetX.w, startLoAndForwardOffsetY.w, startNormalAndForwardOffsetZ.w));\n    vec3 forwardEc2D = czm_normal * normalize(vec3(0.0, offsetAndRight2D.xy));\n\n    // End plane\n    vec4 endPlane2D;\n    vec4 endPlane3D;\n    endPlane2D.xyz = czm_normal * vec3(0.0, startEndNormals2D.zw);\n    endPlane3D.xyz = czm_normal * endNormalAndTextureCoordinateNormalizationX.xyz;\n    endPlane2D.w = -dot(endPlane2D.xyz, posEc2D);\n    endPlane3D.w = -dot(endPlane3D.xyz, posEc3D);\n\n    // Forward direction\n    v_forwardDirectionEC = normalize(endEC - startEC);\n\n    vec2 cleanTexcoordNormalization2D;\n    cleanTexcoordNormalization2D.x = abs(texcoordNormalization2D.x);\n    cleanTexcoordNormalization2D.y = czm_branchFreeTernary(texcoordNormalization2D.y > 1.0, 0.0, abs(texcoordNormalization2D.y));\n    vec2 cleanTexcoordNormalization3D;\n    cleanTexcoordNormalization3D.x = abs(endNormalAndTextureCoordinateNormalizationX.w);\n    cleanTexcoordNormalization3D.y = rightNormalAndTextureCoordinateNormalizationY.w;\n    cleanTexcoordNormalization3D.y = czm_branchFreeTernary(cleanTexcoordNormalization3D.y > 1.0, 0.0, abs(cleanTexcoordNormalization3D.y));\n\n    v_texcoordNormalizationAndHalfWidth.xy = mix(cleanTexcoordNormalization2D, cleanTexcoordNormalization3D, czm_morphTime);\n\n#ifdef PER_INSTANCE_COLOR\n    v_color = czm_batchTable_color(batchId);\n#else // PER_INSTANCE_COLOR\n    // For computing texture coordinates\n\n    v_alignedPlaneDistances.x = -dot(v_forwardDirectionEC, startEC);\n    v_alignedPlaneDistances.y = -dot(-v_forwardDirectionEC, endEC);\n#endif // PER_INSTANCE_COLOR\n\n#ifdef WIDTH_VARYING\n    float width = czm_batchTable_width(batchId);\n    float halfWidth = width * 0.5;\n    v_width = width;\n    v_texcoordNormalizationAndHalfWidth.z = halfWidth;\n#else\n    float halfWidth = 0.5 * czm_batchTable_width(batchId);\n    v_texcoordNormalizationAndHalfWidth.z = halfWidth;\n#endif\n\n    // Compute a normal along which to "push" the position out, extending the miter depending on view distance.\n    // Position has already been "pushed" by unit length along miter normal, and miter normals are encoded in the planes.\n    // Decode the normal to use at this specific vertex, push the position back, and then push to where it needs to be.\n    // Since this is morphing, compute both 3D and 2D positions and then blend.\n\n    // ****** 3D ******\n    // Check distance to the end plane and start plane, pick the plane that is closer\n    vec4 positionEc3D = czm_modelViewRelativeToEye * czm_translateRelativeToEye(position3DHigh, position3DLow); // w = 1.0, see czm_computePosition\n    float absStartPlaneDistance = abs(czm_planeDistance(startPlane3D, positionEc3D.xyz));\n    float absEndPlaneDistance = abs(czm_planeDistance(endPlane3D, positionEc3D.xyz));\n    vec3 planeDirection = czm_branchFreeTernary(absStartPlaneDistance < absEndPlaneDistance, startPlane3D.xyz, endPlane3D.xyz);\n    vec3 upOrDown = normalize(cross(rightPlane3D.xyz, planeDirection)); // Points "up" for start plane, "down" at end plane.\n    vec3 normalEC = normalize(cross(planeDirection, upOrDown));         // In practice, the opposite seems to work too.\n\n    // Nudge the top vertex upwards to prevent flickering\n    vec3 geodeticSurfaceNormal = normalize(cross(normalEC, forwardEc3D));\n    geodeticSurfaceNormal *= float(0.0 <= rightNormalAndTextureCoordinateNormalizationY.w && rightNormalAndTextureCoordinateNormalizationY.w <= 1.0);\n    geodeticSurfaceNormal *= MAX_TERRAIN_HEIGHT;\n    positionEc3D.xyz += geodeticSurfaceNormal;\n\n    // Determine if this vertex is on the "left" or "right"\n    normalEC *= sign(endNormalAndTextureCoordinateNormalizationX.w);\n\n    // A "perfect" implementation would push along normals according to the angle against forward.\n    // In practice, just pushing the normal out by halfWidth is sufficient for morph views.\n    positionEc3D.xyz += halfWidth * max(0.0, czm_metersPerPixel(positionEc3D)) * normalEC; // prevent artifacts when czm_metersPerPixel is negative (behind camera)\n\n    // ****** 2D ******\n    // Check distance to the end plane and start plane, pick the plane that is closer\n    vec4 positionEc2D = czm_modelViewRelativeToEye * czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy); // w = 1.0, see czm_computePosition\n    absStartPlaneDistance = abs(czm_planeDistance(startPlane2D, positionEc2D.xyz));\n    absEndPlaneDistance = abs(czm_planeDistance(endPlane2D, positionEc2D.xyz));\n    planeDirection = czm_branchFreeTernary(absStartPlaneDistance < absEndPlaneDistance, startPlane2D.xyz, endPlane2D.xyz);\n    upOrDown = normalize(cross(rightPlane2D.xyz, planeDirection)); // Points "up" for start plane, "down" at end plane.\n    normalEC = normalize(cross(planeDirection, upOrDown));         // In practice, the opposite seems to work too.\n\n    // Nudge the top vertex upwards to prevent flickering\n    geodeticSurfaceNormal = normalize(cross(normalEC, forwardEc2D));\n    geodeticSurfaceNormal *= float(0.0 <= texcoordNormalization2D.y && texcoordNormalization2D.y <= 1.0);\n    geodeticSurfaceNormal *= MAX_TERRAIN_HEIGHT;\n    positionEc2D.xyz += geodeticSurfaceNormal;\n\n    // Determine if this vertex is on the "left" or "right"\n    normalEC *= sign(texcoordNormalization2D.x);\n#ifndef PER_INSTANCE_COLOR\n    // Use vertex\'s sidedness to compute its texture coordinate.\n    v_texcoordT = clamp(sign(texcoordNormalization2D.x), 0.0, 1.0);\n#endif\n\n    // A "perfect" implementation would push along normals according to the angle against forward.\n    // In practice, just pushing the normal out by halfWidth is sufficient for morph views.\n    positionEc2D.xyz += halfWidth * max(0.0, czm_metersPerPixel(positionEc2D)) * normalEC; // prevent artifacts when czm_metersPerPixel is negative (behind camera)\n\n    // Blend for actual position\n    gl_Position = czm_projection * mix(positionEc2D, positionEc3D, czm_morphTime);\n\n#ifdef ANGLE_VARYING\n    // Approximate relative screen space direction of the line.\n    vec2 approxLineDirection = normalize(vec2(v_forwardDirectionEC.x, -v_forwardDirectionEC.y));\n    approxLineDirection.y = czm_branchFreeTernary(approxLineDirection.x == 0.0 && approxLineDirection.y == 0.0, -1.0, approxLineDirection.y);\n    v_polylineAngle = czm_fastApproximateAtan(approxLineDirection.x, approxLineDirection.y);\n#endif\n}\n'}}]);